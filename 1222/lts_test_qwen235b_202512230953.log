nohup: ignoring input
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2025-12-23 01:53:59] WARNING model_config.py:340: Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:53:59] WARNING model_config.py:812: modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:53:59] WARNING server_args.py:1769: DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[2025-12-23 01:53:59] WARNING server_args.py:1822: DeepEP MoE is enabled. The expert parallel size is adjusted to be the same as the tensor parallel size[16].
[2025-12-23 01:53:59] WARNING server_args.py:1964: Beta spec is enabled for eagle speculative decoding and overlap schedule is turned on.
[2025-12-23 01:53:59] WARNING server_args.py:2029: speculative_num_draft_tokens is adjusted to speculative_num_steps + 1 when speculative_eagle_topk == 1
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:53:59] server_args=ServerArgs(model_path='/data/ascend-ci-share-pkking-sglang/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', tokenizer_path='/data/ascend-ci-share-pkking-sglang/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=65536, is_embedding=False, enable_multimodal=None, limit_mm_data_per_request=None, revision=None, model_impl='auto', host='127.0.0.1', port=21000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='bfloat16', quantization='modelslim', quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, rl_quant_profile=None, mem_fraction_static=0.78, max_running_requests=480, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=2048, enable_dynamic_chunking=False, max_prefill_tokens=16384, prefill_max_requests=None, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=128, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='npu', tp_size=16, pp_size=1, pp_max_micro_batch_size=None, pp_async_batch_depth=0, stream_interval=1, stream_output=False, random_seed=430866580, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, soft_watchdog_timeout=None, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, custom_sigquit_handler=None, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='/data/ascend-ci-share-pkking-sglang/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=16, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='ascend', decode_attention_backend='ascend', prefill_attention_backend='ascend', sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, fp8_gemm_runner_backend='auto', nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', disable_flashinfer_autotune=False, speculative_algorithm='EAGLE', speculative_draft_model_path='/data/ascend-ci-share-pkking-sglang/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', speculative_draft_model_revision='main', speculative_draft_load_format=None, speculative_num_steps=1, speculative_eagle_topk=1, speculative_num_draft_tokens=2, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_draft_attention_backend=None, speculative_moe_runner_backend='auto', speculative_moe_a2a_backend=None, speculative_draft_model_quantization=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, enable_mtp=False, ep_size=16, moe_a2a_backend='deepep', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, mamba_scheduler_strategy='no_buffer', mamba_track_interval=256, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, dllm_algorithm=None, dllm_algorithm_config=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=True, cuda_graph_max_bs=30, cuda_graph_bs=[6, 8, 10, 12, 15, 18, 28, 30], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=True, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=True, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, enable_torch_compile_debug_mode=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, enable_return_routed_experts=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_fused_qk_norm_rope=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, encoder_only=False, language_only=False, encoder_transfer_backend='zmq_to_scheduler', encoder_urls=[], custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, remote_instance_weight_loader_backend='nccl', remote_instance_weight_loader_start_seed_via_transfer_engine=False, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, enable_prefix_mm_cache=False, mm_enable_dp_encoder=False, mm_process_config={}, decrypted_config_file=None, decrypted_draft_config_file=None, forward_hooks=None)
[2025-12-23 01:53:59] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:53:59] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:00] Using default HuggingFace chat template with detected content format: string
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2025-12-23 01:54:17 DP1 TP1 EP1] Process 99727 gpu_id 1 is running on CPUs: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
[2025-12-23 01:54:17 DP1 TP1 EP1] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP1 TP1 EP1] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP6 TP6 EP6] Process 99732 gpu_id 6 is running on CPUs: [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]
[2025-12-23 01:54:17 DP6 TP6 EP6] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP6 TP6 EP6] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2025-12-23 01:54:17 DP7 TP7 EP7] Process 99733 gpu_id 7 is running on CPUs: [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP7 TP7 EP7] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP7 TP7 EP7] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP8 TP8 EP8] Process 99734 gpu_id 8 is running on CPUs: [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]
[2025-12-23 01:54:17 DP3 TP3 EP3] Process 99729 gpu_id 3 is running on CPUs: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[2025-12-23 01:54:17 DP8 TP8 EP8] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP8 TP8 EP8] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:17 DP3 TP3 EP3] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP3 TP3 EP3] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP4 TP4 EP4] Process 99730 gpu_id 4 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
[2025-12-23 01:54:17 DP4 TP4 EP4] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP4 TP4 EP4] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP5 TP5 EP5] Process 99731 gpu_id 5 is running on CPUs: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]
[2025-12-23 01:54:17 DP5 TP5 EP5] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP5 TP5 EP5] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:17 DP9 TP9 EP9] Process 99735 gpu_id 9 is running on CPUs: [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
[2025-12-23 01:54:17 DP9 TP9 EP9] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP9 TP9 EP9] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
[2025-12-23 01:54:17 DP0 TP0 EP0] Process 99726 gpu_id 0 is running on CPUs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2025-12-23 01:54:17 DP0 TP0 EP0] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:17 DP0 TP0 EP0] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2025-12-23 01:54:18 DP1 TP1 EP1] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP1 TP1 EP1] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP1 TP1 EP1] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2025-12-23 01:54:18 DP10 TP10 EP10] Process 99736 gpu_id 10 is running on CPUs: [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219]
[2025-12-23 01:54:18 DP10 TP10 EP10] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP10 TP10 EP10] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2025-12-23 01:54:18 DP6 TP6 EP6] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP6 TP6 EP6] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP6 TP6 EP6] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2025-12-23 01:54:18 DP7 TP7 EP7] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP7 TP7 EP7] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP7 TP7 EP7] Init torch distributed begin.
[2025-12-23 01:54:18 DP8 TP8 EP8] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP8 TP8 EP8] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP8 TP8 EP8] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:18 DP3 TP3 EP3] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP3 TP3 EP3] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP3 TP3 EP3] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:18 DP4 TP4 EP4] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP4 TP4 EP4] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP4 TP4 EP4] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2025-12-23 01:54:18 DP14 TP14 EP14] Process 100433 gpu_id 14 is running on CPUs: [280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]
[2025-12-23 01:54:18 DP14 TP14 EP14] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP14 TP14 EP14] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP5 TP5 EP5] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP5 TP5 EP5] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP5 TP5 EP5] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:18 DP9 TP9 EP9] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP9 TP9 EP9] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP9 TP9 EP9] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:18 DP0 TP0 EP0] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP0 TP0 EP0] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP0 TP0 EP0] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:18 DP12 TP12 EP12] Process 100431 gpu_id 12 is running on CPUs: [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259]
[2025-12-23 01:54:18 DP12 TP12 EP12] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP12 TP12 EP12] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP2 TP2 EP2] Process 99728 gpu_id 2 is running on CPUs: [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
[2025-12-23 01:54:18 DP2 TP2 EP2] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP2 TP2 EP2] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2025-12-23 01:54:18 DP13 TP13 EP13] Process 100432 gpu_id 13 is running on CPUs: [260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]
[2025-12-23 01:54:18 DP11 TP11 EP11] Process 100430 gpu_id 11 is running on CPUs: [220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
[2025-12-23 01:54:18 DP13 TP13 EP13] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP13 TP13 EP13] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP15 TP15 EP15] Process 100434 gpu_id 15 is running on CPUs: [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319]
[2025-12-23 01:54:18 DP11 TP11 EP11] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP15 TP15 EP15] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP11 TP11 EP11] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP15 TP15 EP15] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP10 TP10 EP10] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:18 DP10 TP10 EP10] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:18 DP10 TP10 EP10] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2025-12-23 01:54:19 DP14 TP14 EP14] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP14 TP14 EP14] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP14 TP14 EP14] Init torch distributed begin.
[2025-12-23 01:54:19 DP12 TP12 EP12] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP12 TP12 EP12] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP12 TP12 EP12] Init torch distributed begin.
[2025-12-23 01:54:19 DP2 TP2 EP2] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP2 TP2 EP2] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP2 TP2 EP2] Init torch distributed begin.
[2025-12-23 01:54:19 DP15 TP15 EP15] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP15 TP15 EP15] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP15 TP15 EP15] Init torch distributed begin.
[2025-12-23 01:54:19 DP13 TP13 EP13] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP13 TP13 EP13] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP13 TP13 EP13] Init torch distributed begin.
[2025-12-23 01:54:19 DP11 TP11 EP11] Warning: User-specified context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:54:19 DP11 TP11 EP11] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2025-12-23 01:54:19 DP11 TP11 EP11] Init torch distributed begin.
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-12-23 01:54:20 DP0 TP0 EP0] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP14 TP14 EP14] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP13 TP13 EP13] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP11 TP11 EP11] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP8 TP8 EP8] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP9 TP9 EP9] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP12 TP12 EP12] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP7 TP7 EP7] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP4 TP4 EP4] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP1 TP1 EP1] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP15 TP15 EP15] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP6 TP6 EP6] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP3 TP3 EP3] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP2 TP2 EP2] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP5 TP5 EP5] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:54:20 DP10 TP10 EP10] Init torch distributed ends. mem usage=0.00 GB
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:21 DP13 TP13 EP13] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP8 TP8 EP8] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP9 TP9 EP9] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP12 TP12 EP12] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP1 TP1 EP1] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP6 TP6 EP6] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP0 TP0 EP0] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP4 TP4 EP4] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP5 TP5 EP5] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP3 TP3 EP3] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP10 TP10 EP10] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP15 TP15 EP15] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP7 TP7 EP7] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP11 TP11 EP11] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP14 TP14 EP14] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP2 TP2 EP2] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2025-12-23 01:54:21 DP1 TP1 EP1] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP5 TP5 EP5] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP7 TP7 EP7] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP14 TP14 EP14] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP11 TP11 EP11] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP12 TP12 EP12] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP3 TP3 EP3] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP8 TP8 EP8] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP9 TP9 EP9] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP4 TP4 EP4] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP13 TP13 EP13] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP6 TP6 EP6] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP10 TP10 EP10] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP0 TP0 EP0] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP2 TP2 EP2] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2025-12-23 01:54:21 DP15 TP15 EP15] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2025-12-23 01:54:22 DP9 TP9 EP9] Load weight begin. avail mem=61.10 GB
[2025-12-23 01:54:22 DP8 TP8 EP8] Load weight begin. avail mem=60.88 GB
[2025-12-23 01:54:22 DP3 TP3 EP3] Load weight begin. avail mem=61.10 GB
[2025-12-23 01:54:22 DP7 TP7 EP7] Load weight begin. avail mem=61.10 GB
[2025-12-23 01:54:23 DP4 TP4 EP4] Load weight begin. avail mem=60.88 GB
[2025-12-23 01:54:23 DP0 TP0 EP0] Load weight begin. avail mem=60.82 GB
[2025-12-23 01:54:23 DP5 TP5 EP5] Load weight begin. avail mem=61.10 GB
[2025-12-23 01:54:23 DP12 TP12 EP12] Load weight begin. avail mem=60.87 GB
[2025-12-23 01:54:23 DP14 TP14 EP14] Load weight begin. avail mem=60.87 GB
[2025-12-23 01:54:23 DP13 TP13 EP13] Load weight begin. avail mem=61.11 GB
[2025-12-23 01:54:23 DP15 TP15 EP15] Load weight begin. avail mem=61.11 GB
[2025-12-23 01:54:23 DP6 TP6 EP6] Load weight begin. avail mem=60.88 GB
[2025-12-23 01:54:23 DP11 TP11 EP11] Load weight begin. avail mem=61.10 GB
[2025-12-23 01:54:23 DP10 TP10 EP10] Load weight begin. avail mem=60.87 GB
[2025-12-23 01:54:23 DP2 TP2 EP2] Load weight begin. avail mem=60.88 GB
[2025-12-23 01:54:23 DP1 TP1 EP1] Load weight begin. avail mem=61.10 GB
Loading safetensors checkpoint shards:   0% Completed | 0/56 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   2% Completed | 1/56 [00:02<02:36,  2.85s/it]
Loading safetensors checkpoint shards:   4% Completed | 2/56 [00:06<02:47,  3.11s/it]
Loading safetensors checkpoint shards:   5% Completed | 3/56 [00:09<02:45,  3.12s/it]
Loading safetensors checkpoint shards:   7% Completed | 4/56 [00:12<02:51,  3.29s/it]
Loading safetensors checkpoint shards:   9% Completed | 5/56 [00:16<02:46,  3.26s/it]
Loading safetensors checkpoint shards:  11% Completed | 6/56 [00:19<02:43,  3.27s/it]
Loading safetensors checkpoint shards:  12% Completed | 7/56 [00:22<02:41,  3.30s/it]
Loading safetensors checkpoint shards:  14% Completed | 8/56 [00:25<02:36,  3.27s/it]
Loading safetensors checkpoint shards:  16% Completed | 9/56 [00:29<02:33,  3.26s/it]
Loading safetensors checkpoint shards:  18% Completed | 10/56 [00:32<02:31,  3.28s/it]
Loading safetensors checkpoint shards:  20% Completed | 11/56 [00:35<02:28,  3.31s/it]
Loading safetensors checkpoint shards:  21% Completed | 12/56 [00:39<02:24,  3.27s/it]
Loading safetensors checkpoint shards:  23% Completed | 13/56 [00:42<02:20,  3.26s/it]
Loading safetensors checkpoint shards:  25% Completed | 14/56 [00:45<02:11,  3.13s/it]
Loading safetensors checkpoint shards:  27% Completed | 15/56 [00:48<02:10,  3.18s/it]
Loading safetensors checkpoint shards:  29% Completed | 16/56 [00:51<02:09,  3.24s/it]
Loading safetensors checkpoint shards:  30% Completed | 17/56 [00:55<02:06,  3.25s/it]
Loading safetensors checkpoint shards:  32% Completed | 18/56 [00:58<02:03,  3.24s/it]
Loading safetensors checkpoint shards:  34% Completed | 19/56 [01:01<01:58,  3.20s/it]
Loading safetensors checkpoint shards:  36% Completed | 20/56 [01:04<01:49,  3.05s/it]
Loading safetensors checkpoint shards:  38% Completed | 21/56 [01:07<01:47,  3.07s/it]
Loading safetensors checkpoint shards:  39% Completed | 22/56 [01:10<01:44,  3.08s/it]
Loading safetensors checkpoint shards:  41% Completed | 23/56 [01:13<01:42,  3.10s/it]
Loading safetensors checkpoint shards:  43% Completed | 24/56 [01:16<01:40,  3.15s/it]
Loading safetensors checkpoint shards:  45% Completed | 25/56 [01:20<01:39,  3.20s/it]
Loading safetensors checkpoint shards:  46% Completed | 26/56 [01:23<01:35,  3.20s/it]
Loading safetensors checkpoint shards:  48% Completed | 27/56 [01:28<01:48,  3.74s/it]
Loading safetensors checkpoint shards:  50% Completed | 28/56 [01:31<01:42,  3.65s/it]
Loading safetensors checkpoint shards:  52% Completed | 29/56 [01:34<01:35,  3.55s/it]
Loading safetensors checkpoint shards:  54% Completed | 30/56 [01:38<01:30,  3.47s/it]
Loading safetensors checkpoint shards:  55% Completed | 31/56 [01:41<01:25,  3.40s/it]
Loading safetensors checkpoint shards:  57% Completed | 32/56 [01:44<01:20,  3.34s/it]
Loading safetensors checkpoint shards:  59% Completed | 33/56 [01:47<01:16,  3.32s/it]
Loading safetensors checkpoint shards:  61% Completed | 34/56 [01:51<01:12,  3.30s/it]
Loading safetensors checkpoint shards:  62% Completed | 35/56 [01:54<01:08,  3.26s/it]
Loading safetensors checkpoint shards:  64% Completed | 36/56 [01:57<01:05,  3.29s/it]
Loading safetensors checkpoint shards:  66% Completed | 37/56 [02:00<01:02,  3.27s/it]
Loading safetensors checkpoint shards:  68% Completed | 38/56 [02:04<00:58,  3.25s/it]
Loading safetensors checkpoint shards:  70% Completed | 39/56 [02:07<00:56,  3.30s/it]
Loading safetensors checkpoint shards:  71% Completed | 40/56 [02:10<00:53,  3.33s/it]
Loading safetensors checkpoint shards:  73% Completed | 41/56 [02:14<00:48,  3.25s/it]
Loading safetensors checkpoint shards:  75% Completed | 42/56 [02:17<00:44,  3.21s/it]
Loading safetensors checkpoint shards:  77% Completed | 43/56 [02:20<00:41,  3.18s/it]
Loading safetensors checkpoint shards:  79% Completed | 44/56 [02:23<00:38,  3.20s/it]
Loading safetensors checkpoint shards:  80% Completed | 45/56 [02:26<00:35,  3.22s/it]
Loading safetensors checkpoint shards:  82% Completed | 46/56 [02:30<00:32,  3.24s/it]
Loading safetensors checkpoint shards:  84% Completed | 47/56 [02:33<00:29,  3.29s/it]
Loading safetensors checkpoint shards:  86% Completed | 48/56 [02:36<00:26,  3.27s/it]
Loading safetensors checkpoint shards:  88% Completed | 49/56 [02:39<00:22,  3.26s/it]
Loading safetensors checkpoint shards:  89% Completed | 50/56 [02:43<00:19,  3.27s/it]
Loading safetensors checkpoint shards:  91% Completed | 51/56 [02:46<00:16,  3.25s/it]
Loading safetensors checkpoint shards:  93% Completed | 52/56 [02:49<00:13,  3.27s/it]
Loading safetensors checkpoint shards:  95% Completed | 53/56 [02:53<00:09,  3.28s/it]
Loading safetensors checkpoint shards:  96% Completed | 54/56 [02:56<00:06,  3.28s/it]
Loading safetensors checkpoint shards:  98% Completed | 55/56 [02:59<00:03,  3.25s/it]
Loading safetensors checkpoint shards: 100% Completed | 56/56 [03:02<00:00,  3.26s/it]
Loading safetensors checkpoint shards: 100% Completed | 56/56 [03:02<00:00,  3.26s/it]

[2025-12-23 01:58:12 DP12 TP12 EP12] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.10 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP14 TP14 EP14] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.10 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP15 TP15 EP15] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.34 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP2 TP2 EP2] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.11 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP8 TP8 EP8] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.11 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP10 TP10 EP10] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.10 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP9 TP9 EP9] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.33 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP13 TP13 EP13] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.34 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP11 TP11 EP11] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.34 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP5 TP5 EP5] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.33 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP0 TP0 EP0] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.04 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP1 TP1 EP1] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.33 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP4 TP4 EP4] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.11 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP7 TP7 EP7] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.33 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP6 TP6 EP6] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.11 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP3 TP3 EP3] Load weight end. type=Qwen3MoeForCausalLM, dtype=torch.bfloat16, avail mem=37.33 GB, mem usage=23.77 GB.
[2025-12-23 01:58:13 DP0 TP0 EP0] Using KV cache dtype: torch.bfloat16
[2025-12-23 01:58:13 DP0 TP0 EP0] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP14 TP14 EP14] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP15 TP15 EP15] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP13 TP13 EP13] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP12 TP12 EP12] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP11 TP11 EP11] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP9 TP9 EP9] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP10 TP10 EP10] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP8 TP8 EP8] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP6 TP6 EP6] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP5 TP5 EP5] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP7 TP7 EP7] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP4 TP4 EP4] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP2 TP2 EP2] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP1 TP1 EP1] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP3 TP3 EP3] The available memory for KV cache is 23.66 GB.
[2025-12-23 01:58:13 DP2 TP2 EP2] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP8 TP8 EP8] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP5 TP5 EP5] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP12 TP12 EP12] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP6 TP6 EP6] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP1 TP1 EP1] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP10 TP10 EP10] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP11 TP11 EP11] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP14 TP14 EP14] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP3 TP3 EP3] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP13 TP13 EP13] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP0 TP0 EP0] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP4 TP4 EP4] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP15 TP15 EP15] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP9 TP9 EP9] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP7 TP7 EP7] KV Cache is allocated. #tokens: 133504, K size: 11.98 GB, V size: 11.98 GB
[2025-12-23 01:58:13 DP2 TP2 EP2] Memory pool end. avail mem=13.03 GB
[2025-12-23 01:58:13 DP8 TP8 EP8] Memory pool end. avail mem=13.03 GB
[2025-12-23 01:58:13 DP12 TP12 EP12] Memory pool end. avail mem=13.02 GB
[2025-12-23 01:58:13 DP6 TP6 EP6] Memory pool end. avail mem=13.03 GB
[2025-12-23 01:58:13 DP5 TP5 EP5] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP1 TP1 EP1] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP11 TP11 EP11] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP10 TP10 EP10] Memory pool end. avail mem=13.02 GB
[2025-12-23 01:58:13 DP14 TP14 EP14] Memory pool end. avail mem=13.02 GB
[2025-12-23 01:58:13 DP3 TP3 EP3] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP13 TP13 EP13] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP0 TP0 EP0] Memory pool end. avail mem=12.96 GB
[2025-12-23 01:58:13 DP4 TP4 EP4] Memory pool end. avail mem=13.03 GB
[2025-12-23 01:58:13 DP15 TP15 EP15] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP7 TP7 EP7] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP9 TP9 EP9] Memory pool end. avail mem=13.25 GB
[2025-12-23 01:58:13 DP5 TP5 EP5] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP6 TP6 EP6] Capture cuda graph begin. This can take up to several minutes. avail mem=13.03 GB
[2025-12-23 01:58:13 DP1 TP1 EP1] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP11 TP11 EP11] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP12 TP12 EP12] Capture cuda graph begin. This can take up to several minutes. avail mem=13.02 GB
[2025-12-23 01:58:13 DP14 TP14 EP14] Capture cuda graph begin. This can take up to several minutes. avail mem=13.02 GB
[2025-12-23 01:58:13 DP13 TP13 EP13] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP10 TP10 EP10] Capture cuda graph begin. This can take up to several minutes. avail mem=13.02 GB
[2025-12-23 01:58:13 DP8 TP8 EP8] Capture cuda graph begin. This can take up to several minutes. avail mem=13.03 GB
[2025-12-23 01:58:13 DP2 TP2 EP2] Capture cuda graph begin. This can take up to several minutes. avail mem=13.03 GB
[2025-12-23 01:58:13 DP3 TP3 EP3] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP0 TP0 EP0] Capture cuda graph begin. This can take up to several minutes. avail mem=12.96 GB
[2025-12-23 01:58:13 DP0 TP0 EP0] Capture cuda graph bs [6, 8, 10, 12, 15, 18, 28, 30]
[2025-12-23 01:58:13 DP4 TP4 EP4] Capture cuda graph begin. This can take up to several minutes. avail mem=13.03 GB
[2025-12-23 01:58:13 DP9 TP9 EP9] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP15 TP15 EP15] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
[2025-12-23 01:58:13 DP7 TP7 EP7] Capture cuda graph begin. This can take up to several minutes. avail mem=13.25 GB
  0%|          | 0/8 [00:00<?, ?it/s]Capturing batches (bs=30 avail_mem=12.91 GB):   0%|          | 0/8 [00:00<?, ?it/s]Capturing batches (bs=30 avail_mem=12.91 GB):  12%|        | 1/8 [00:08<01:02,  8.94s/it]Capturing batches (bs=28 avail_mem=9.30 GB):  12%|        | 1/8 [00:08<01:02,  8.94s/it] Capturing batches (bs=28 avail_mem=9.30 GB):  25%|       | 2/8 [00:09<00:24,  4.04s/it]Capturing batches (bs=18 avail_mem=9.30 GB):  25%|       | 2/8 [00:09<00:24,  4.04s/it]Capturing batches (bs=18 avail_mem=9.30 GB):  38%|      | 3/8 [00:10<00:12,  2.47s/it]Capturing batches (bs=15 avail_mem=9.29 GB):  38%|      | 3/8 [00:10<00:12,  2.47s/it]Capturing batches (bs=15 avail_mem=9.29 GB):  50%|     | 4/8 [00:10<00:06,  1.75s/it]Capturing batches (bs=12 avail_mem=9.28 GB):  50%|     | 4/8 [00:10<00:06,  1.75s/it]Capturing batches (bs=12 avail_mem=9.28 GB):  62%|   | 5/8 [00:11<00:04,  1.34s/it]Capturing batches (bs=10 avail_mem=9.27 GB):  62%|   | 5/8 [00:11<00:04,  1.34s/it]Capturing batches (bs=10 avail_mem=9.27 GB):  75%|  | 6/8 [00:12<00:02,  1.10s/it]Capturing batches (bs=8 avail_mem=9.26 GB):  75%|  | 6/8 [00:12<00:02,  1.10s/it] Capturing batches (bs=8 avail_mem=9.26 GB):  88%| | 7/8 [00:12<00:00,  1.07it/s]Capturing batches (bs=6 avail_mem=9.25 GB):  88%| | 7/8 [00:12<00:00,  1.07it/s]Capturing batches (bs=6 avail_mem=9.25 GB): 100%|| 8/8 [00:13<00:00,  1.16it/s]Capturing batches (bs=6 avail_mem=9.25 GB): 100%|| 8/8 [00:13<00:00,  1.67s/it]
[2025-12-23 01:58:27 DP14 TP14 EP14] Capture cuda graph end. Time elapsed: 14.16 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:27 DP9 TP9 EP9] Capture cuda graph end. Time elapsed: 14.20 s. mem usage=3.72 GB. avail mem=9.53 GB.
[2025-12-23 01:58:27 DP8 TP8 EP8] Capture cuda graph end. Time elapsed: 14.20 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:27 DP13 TP13 EP13] Capture cuda graph end. Time elapsed: 14.25 s. mem usage=3.72 GB. avail mem=9.54 GB.
[2025-12-23 01:58:27 DP12 TP12 EP12] Capture cuda graph end. Time elapsed: 14.31 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:27 DP11 TP11 EP11] Capture cuda graph end. Time elapsed: 14.31 s. mem usage=3.72 GB. avail mem=9.54 GB.
[2025-12-23 01:58:27 DP0 TP0 EP0] Capture cuda graph end. Time elapsed: 14.32 s. mem usage=3.72 GB. avail mem=9.25 GB.
[2025-12-23 01:58:27 DP10 TP10 EP10] Capture cuda graph end. Time elapsed: 14.33 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:27 DP5 TP5 EP5] Capture cuda graph end. Time elapsed: 14.33 s. mem usage=3.72 GB. avail mem=9.53 GB.
[2025-12-23 01:58:27 DP6 TP6 EP6] Capture cuda graph end. Time elapsed: 14.40 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:27 DP2 TP2 EP2] Capture cuda graph end. Time elapsed: 14.41 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:28 DP3 TP3 EP3] Capture cuda graph end. Time elapsed: 14.43 s. mem usage=3.72 GB. avail mem=9.53 GB.
[2025-12-23 01:58:28 DP4 TP4 EP4] Capture cuda graph end. Time elapsed: 14.43 s. mem usage=3.72 GB. avail mem=9.31 GB.
[2025-12-23 01:58:28 DP1 TP1 EP1] Capture cuda graph end. Time elapsed: 14.45 s. mem usage=3.72 GB. avail mem=9.54 GB.
[2025-12-23 01:58:28 DP7 TP7 EP7] Capture cuda graph end. Time elapsed: 14.46 s. mem usage=3.72 GB. avail mem=9.53 GB.
[2025-12-23 01:58:28 DP15 TP15 EP15] Capture cuda graph end. Time elapsed: 14.52 s. mem usage=3.72 GB. avail mem=9.54 GB.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:1204: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)
  tensor_data = torch.ByteTensor(
[2025-12-23 01:58:28 DP8 TP8 EP8] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP12 TP12 EP12] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP13 TP13 EP13] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP4 TP4 EP4] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP5 TP5 EP5] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP9 TP9 EP9] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP0 TP0 EP0] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP14 TP14 EP14] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP10 TP10 EP10] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP6 TP6 EP6] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP8 TP8 EP8] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP2 TP2 EP2] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP12 TP12 EP12] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP13 TP13 EP13] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP4 TP4 EP4] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP5 TP5 EP5] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP9 TP9 EP9] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP0 TP0 EP0] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP14 TP14 EP14] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP10 TP10 EP10] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP6 TP6 EP6] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP2 TP2 EP2] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP11 TP11 EP11] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP11 TP11 EP11] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP1 TP1 EP1] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP1 TP1 EP1] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP8 TP8 EP8] Init torch distributed begin.
[2025-12-23 01:58:28 DP9 TP9 EP9] Init torch distributed begin.
[2025-12-23 01:58:28 DP11 TP11 EP11] Init torch distributed begin.
[2025-12-23 01:58:28 DP10 TP10 EP10] Init torch distributed begin.
[2025-12-23 01:58:28 DP12 TP12 EP12] Init torch distributed begin.
[2025-12-23 01:58:28 DP5 TP5 EP5] Init torch distributed begin.
[2025-12-23 01:58:28 DP13 TP13 EP13] Init torch distributed begin.
[2025-12-23 01:58:28 DP2 TP2 EP2] Init torch distributed begin.
[2025-12-23 01:58:28 DP4 TP4 EP4] Init torch distributed begin.
[2025-12-23 01:58:28 DP0 TP0 EP0] Init torch distributed begin.
[2025-12-23 01:58:28 DP6 TP6 EP6] Init torch distributed begin.
[2025-12-23 01:58:28 DP1 TP1 EP1] Init torch distributed begin.
[2025-12-23 01:58:28 DP14 TP14 EP14] Init torch distributed begin.
[2025-12-23 01:58:28 DP7 TP7 EP7] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP7 TP7 EP7] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP15 TP15 EP15] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP3 TP3 EP3] Warning: Target model's context_length (65536) is greater than the derived context_length (40960). This may lead to incorrect model outputs or CUDA errors. Note that the derived context_length may differ from max_position_embeddings in the model's config.
[2025-12-23 01:58:28 DP15 TP15 EP15] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP3 TP3 EP3] Overriding the draft model's max_position_embeddings to 65536.
[2025-12-23 01:58:28 DP7 TP7 EP7] Init torch distributed begin.
[2025-12-23 01:58:28 DP15 TP15 EP15] Init torch distributed begin.
[2025-12-23 01:58:28 DP3 TP3 EP3] Init torch distributed begin.
[2025-12-23 01:58:28 DP0 TP0 EP0] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP15 TP15 EP15] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP14 TP14 EP14] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP13 TP13 EP13] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP12 TP12 EP12] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP11 TP11 EP11] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP10 TP10 EP10] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP9 TP9 EP9] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP8 TP8 EP8] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP7 TP7 EP7] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP6 TP6 EP6] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP5 TP5 EP5] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP4 TP4 EP4] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP3 TP3 EP3] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP2 TP2 EP2] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP1 TP1 EP1] Init torch distributed ends. mem usage=0.00 GB
[2025-12-23 01:58:28 DP0 TP0 EP0] Load weight begin. avail mem=9.25 GB
[2025-12-23 01:58:28 DP14 TP14 EP14] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP12 TP12 EP12] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP15 TP15 EP15] Load weight begin. avail mem=9.54 GB
[2025-12-23 01:58:28 DP10 TP10 EP10] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP11 TP11 EP11] Load weight begin. avail mem=9.54 GB
[2025-12-23 01:58:28 DP8 TP8 EP8] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP4 TP4 EP4] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP9 TP9 EP9] Load weight begin. avail mem=9.53 GB
[2025-12-23 01:58:28 DP7 TP7 EP7] Load weight begin. avail mem=9.53 GB
[2025-12-23 01:58:28 DP2 TP2 EP2] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP1 TP1 EP1] Load weight begin. avail mem=9.54 GB
[2025-12-23 01:58:28 DP6 TP6 EP6] Load weight begin. avail mem=9.31 GB
[2025-12-23 01:58:28 DP5 TP5 EP5] Load weight begin. avail mem=9.53 GB
[2025-12-23 01:58:28 DP13 TP13 EP13] Load weight begin. avail mem=9.54 GB
[2025-12-23 01:58:28 DP3 TP3 EP3] Load weight begin. avail mem=9.53 GB
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.52it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.51it/s]

[2025-12-23 01:58:29 DP0 TP0 EP0] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=8.99 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP1 TP1 EP1] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP14 TP14 EP14] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.05 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP6 TP6 EP6] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.06 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP5 TP5 EP5] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP7 TP7 EP7] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP15 TP15 EP15] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP4 TP4 EP4] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.06 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP8 TP8 EP8] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.06 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP3 TP3 EP3] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP2 TP2 EP2] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.05 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP12 TP12 EP12] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.05 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP13 TP13 EP13] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP10 TP10 EP10] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.05 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP11 TP11 EP11] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.28 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP9 TP9 EP9] Load weight end. type=LlamaForCausalLMEagle3, dtype=torch.bfloat16, avail mem=9.27 GB, mem usage=0.26 GB.
[2025-12-23 01:58:29 DP0 TP0 EP0] Using KV cache dtype: torch.bfloat16
[2025-12-23 01:58:29 DP0 TP0 EP0] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP15 TP15 EP15] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP14 TP14 EP14] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP13 TP13 EP13] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP12 TP12 EP12] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP11 TP11 EP11] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP10 TP10 EP10] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP9 TP9 EP9] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP8 TP8 EP8] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP7 TP7 EP7] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP6 TP6 EP6] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP5 TP5 EP5] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP4 TP4 EP4] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP3 TP3 EP3] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP2 TP2 EP2] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP1 TP1 EP1] The available memory for KV cache is 6.98 GB.
[2025-12-23 01:58:29 DP0 TP0 EP0] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP12 TP12 EP12] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP14 TP14 EP14] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP13 TP13 EP13] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP15 TP15 EP15] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP11 TP11 EP11] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP10 TP10 EP10] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP8 TP8 EP8] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP5 TP5 EP5] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP9 TP9 EP9] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP4 TP4 EP4] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP7 TP7 EP7] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP6 TP6 EP6] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP2 TP2 EP2] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP3 TP3 EP3] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP1 TP1 EP1] KV Cache is allocated. #tokens: 133504, K size: 0.13 GB, V size: 0.13 GB
[2025-12-23 01:58:29 DP0 TP0 EP0] Memory pool end. avail mem=8.76 GB
[2025-12-23 01:58:29 DP14 TP14 EP14] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP12 TP12 EP12] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP13 TP13 EP13] Memory pool end. avail mem=9.05 GB
[2025-12-23 01:58:29 DP15 TP15 EP15] Memory pool end. avail mem=9.05 GB
[2025-12-23 01:58:29 DP11 TP11 EP11] Memory pool end. avail mem=9.05 GB
[2025-12-23 01:58:29 DP10 TP10 EP10] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP8 TP8 EP8] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP4 TP4 EP4] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP9 TP9 EP9] Memory pool end. avail mem=9.04 GB
[2025-12-23 01:58:29 DP6 TP6 EP6] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP5 TP5 EP5] Memory pool end. avail mem=9.04 GB
[2025-12-23 01:58:29 DP7 TP7 EP7] Memory pool end. avail mem=9.04 GB
[2025-12-23 01:58:29 DP2 TP2 EP2] Memory pool end. avail mem=8.82 GB
[2025-12-23 01:58:29 DP3 TP3 EP3] Memory pool end. avail mem=9.04 GB
[2025-12-23 01:58:29 DP1 TP1 EP1] Memory pool end. avail mem=9.05 GB
[2025-12-23 01:58:29 DP2 TP2 EP2] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.94 GB
[2025-12-23 01:58:29 DP8 TP8 EP8] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.94 GB
[2025-12-23 01:58:29 DP3 TP3 EP3] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.16 GB
[2025-12-23 01:58:29 DP5 TP5 EP5] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.16 GB
[2025-12-23 01:58:29 DP9 TP9 EP9] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.16 GB
[2025-12-23 01:58:29 DP4 TP4 EP4] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.94 GB
[2025-12-23 01:58:29 DP0 TP0 EP0] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.87 GB
[2025-12-23 01:58:29 DP1 TP1 EP1] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.16 GB
[2025-12-23 01:58:29 DP11 TP11 EP11] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.17 GB
[2025-12-23 01:58:29 DP14 TP14 EP14] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.93 GB
[2025-12-23 01:58:29 DP6 TP6 EP6] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.94 GB
[2025-12-23 01:58:29 DP15 TP15 EP15] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.17 GB
[2025-12-23 01:58:29 DP12 TP12 EP12] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.93 GB
[2025-12-23 01:58:29 DP7 TP7 EP7] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.16 GB
[2025-12-23 01:58:29 DP13 TP13 EP13] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=9.17 GB
[2025-12-23 01:58:29 DP10 TP10 EP10] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=8.93 GB
  0%|          | 0/8 [00:00<?, ?it/s]Capturing batches (bs=30 avail_mem=8.85 GB):   0%|          | 0/8 [00:00<?, ?it/s]................mki_log delete old file:/root/ascend/log/atb/atb_394311_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394309_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394305_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394305_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394305_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395009_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394307_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395009_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395013_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394307_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395009_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394314_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395013_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394307_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394314_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394315_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394314_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_395013_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394315_20251222081852.log
mki_log delete old file:/root/ascend/log/atb/atb_394315_20251222081852.log
Fatal Python error: Segmentation fault

Thread 0x0000fff783fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 331 in wait
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 629 in wait
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff913fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff92bfff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff937fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff943fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff94ffef120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff953fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff95ce5f120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff960e6f120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 327 in wait
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line 231 in _feed
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff973fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 395 in _recv
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430 in _recv_bytes
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250 in recv
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822 in _callmethod
  File "<string>", line 2 in get
  File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff987fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 331 in wait
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 629 in wait
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fffcc591f120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 61 in _recv_msg
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 195 in _read_thread
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000ffff84e73840 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py", line 358 in get_current_stream
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py", line 592 in run
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py", line 773 in warmup
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py", line 115 in add_rmsnorm_bias
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py", line 53 in _rmsnorm_forward_oot
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py", line 67 in forward
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784 in _call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773 in _wrapped_call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py", line 96 in forward
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784 in _call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773 in _wrapped_call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py", line 170 in forward
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784 in _call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773 in _wrapped_call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py", line 469 in forward
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120 in decorate_context
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line 349 in run_once
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py", line 47 in _capture_init
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line 361 in capture_one_batch_size
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 500 in _capture_one_stream
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py", line 513 in capture
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line 229 in capture
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line 181 in __init__
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py", line 35 in __init__
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 261 in init_cuda_graphs
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 148 in __init__
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 580 in __init__
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py", line 269 in _create_eagle_worker
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py", line 197 in _factory
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py", line 179 in create_draft_worker
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 514 in init_model_worker
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 315 in __init__
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2828 in run_scheduler_process
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py", line 108 in run
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py", line 314 in _bootstrap
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", line 135 in _main
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", line 122 in spawn_main
  File "<string>", line 1 in <module>

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, pybase64._pybase64, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._pcg64, numpy.random._generator, numpy.random._mt19937, numpy.random._philox, numpy.random._sfc64, numpy.random.mtrand, acl, torch_npu._C, markupsafe._speedups, yaml._yaml, psutil._psutil_linux, zmq.backend.cython._zmq, cython.cimports.libc.math, PIL._imaging, sentencepiece._sentencepiece, regex._regex, npu_utils, PIL._imagingft, _cffi_backend, scipy._lib._ccallback_c, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.optimize._group_columns, scipy._lib.messagestream, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._cython_nnls, scipy._lib._uarray._uarray, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.spatial._ckdtree, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.optimize._direct, setproctitle._setproctitle, Cython.Utils, Cython.Plex.Actions, Cython.Plex.Transitions, Cython.Plex.Machines, Cython.Plex.DFA, Cython.Plex.Scanners, Cython.Compiler.Scanning, Cython.StringIOTree, Cython.Compiler.Code, google._upb._message, msgspec._core, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, xxhash._xxhash, pyarrow._acero, pyarrow._csv, pyarrow._json, pyarrow._substrait, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, __triton_launcher (total: 174)
Fatal Python error: Segmentation fault

Thread 0x0000fff7a3fff120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 331 in wait
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 629 in wait
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py", line 60 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py"Fatal Python error: , line Segmentation fault1002

 in _bootstrapThread 0x
0000fff79ffff120
 (most recent call first):
Thread 0x  File 0000fff93bfff120" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py331" in , line wait327
 in   File wait"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py629" in , line wait231
 in   File _feed"
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py60" in , line run982
 in   File run"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py1045" in , line _bootstrap_inner1045
 in   File _bootstrap_inner"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py1002" in , line _bootstrap1002
 in 
_bootstrapThread 0x
0000fff93ffcf120
 (most recent call first):
Thread 0x  File 0000fff947fff120" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py327" in , line wait327
 in   File wait"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231" in , line _feed231
 in   File _feed"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py982" in , line run982
 in   File run"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py1045" in , line Fatal Python error: _bootstrap_inner1045Segmentation fault
 in 

  File _bootstrap_inner"Thread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff7b7fff120Fatal Python error:   File " (most recent call first):
Segmentation fault", line   File 

/usr/local/python3.11.13/lib/python3.11/threading.py1002""Thread 0x in /usr/local/python3.11.13/lib/python3.11/threading.py, line 0000fff79bfff120_bootstrap"1002 (most recent call first):

, line  in   File 
331_bootstrap"Thread 0x in 
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff943fdf120wait
" (most recent call first):

Thread 0x, line   File   File 0000fff953fff120331"" (most recent call first):
 in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File wait"""
, line , line /usr/local/python3.11.13/lib/python3.11/threading.py  File 327629"" in  in , line /usr/local/python3.11.13/lib/python3.11/threading.pywaitwait327"

 in , line   File   File wait629""
 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py  File wait"""
, line , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File 23160"" in  in , line /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py_feedrun231"

 in , line Fatal Python error:   File   File _feed60Segmentation fault""
 in 

/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File runThread 0x"""
0000fff783fff120Fatal Python error: , line , line /usr/local/python3.11.13/lib/python3.11/threading.py  File  (most recent call first):
Segmentation fault9821045""  File 

 in  in , line /usr/local/python3.11.13/lib/python3.11/threading.pyFatal Python error: "Thread 0xrun_bootstrap_inner982"Segmentation fault/usr/local/python3.11.13/lib/python3.11/threading.py0000fff797fff120

 in , line 

" (most recent call first):
  File   File run1045Thread 0x, line   File ""
 in 0000fff7abfff120331"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File Fatal Python error: _bootstrap_inner (most recent call first):
 in /usr/local/python3.11.13/lib/python3.11/threading.py"""Segmentation fault
  File wait", line , line /usr/local/python3.11.13/lib/python3.11/threading.py

  File "
, line 10451002"Thread 0x"/usr/local/python3.11.13/lib/python3.11/threading.py  File 331 in  in , line 0000fff7abfff120/usr/local/python3.11.13/lib/python3.11/threading.py"" in _bootstrap_inner_bootstrap1045 (most recent call first):
", line /usr/local/python3.11.13/lib/python3.11/threading.pywait

 in   File , line 331"
  File 
_bootstrap_inner"1002 in Fatal Python error: , line   File "Thread 0x
/usr/local/python3.11.13/lib/python3.11/threading.pyFatal Python error:  in waitSegmentation fault629"/usr/local/python3.11.13/lib/python3.11/threading.py0000fff947fff120  File "Segmentation fault_bootstrapFatal Python error: 


 in /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
", line 


Segmentation fault  File Fatal Python error: Thread 0xwait", line   File /usr/local/python3.11.13/lib/python3.11/threading.py331Thread 0x


"Segmentation fault0000fff8f7fff120
, line 1002"" in 0000fff783fff120Thread 0xThread 0x/usr/local/python3.11.13/lib/python3.11/threading.py

Fatal Python error:  (most recent call first):
  File 629 in /usr/local/python3.11.13/lib/python3.11/threading.py, line wait (most recent call first):
0000fff933fff1200000fff7b3fff120"Thread 0xSegmentation fault  File " in _bootstrap"1002
  File  (most recent call first):
 (most recent call first):
, line 0000fff783fff120

"Thread 0x/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.pywait
, line  in   File "  File   File 629 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff77ffff120"

327_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py"" in   File " (most recent call first):
, line   File Thread 0x in 
/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pywait", line   File 60"0000fff947fef120wait
", line ""
/usr/local/python3.11.13/lib/python3.11/threading.py331" in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py (most recent call first):

Thread 0x, line 331, line , line   File " in /usr/local/python3.11.13/lib/python3.11/threading.pyrun"  File   File 0000fff95ffff120629 in 327Fatal Python error: 331", line wait"
, line "" (most recent call first):
 in wait in Segmentation fault in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py331
, line   File 60Fatal Python error: /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File wait
wait

wait" in   File 331" in Segmentation fault"""
  File 
Thread 0x
, line wait" in /usr/local/python3.11.13/lib/python3.11/threading.pyrun

, line , line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File 0000fff78ffff120  File 60
/usr/local/python3.11.13/lib/python3.11/threading.pywait"
Thread 0x327231""/usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
" in   File "
, line   File 0000fff783fff120 in  in , line /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File /usr/local/python3.11.13/lib/python3.11/threading.pyrun", line   File 1045" (most recent call first):
wait_feed327", line """
/usr/local/python3.11.13/lib/python3.11/threading.py629" in /usr/local/python3.11.13/lib/python3.11/threading.py  File 

 in , line 629, line /usr/local/python3.11.13/lib/python3.11/threading.py, line   File " in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner""  File   File wait60 in 231"629", line wait"
, line /usr/local/python3.11.13/lib/python3.11/threading.py""
 in wait in , line  in /usr/local/python3.11.13/lib/python3.11/threading.py629
, line   File 1045"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py  File run
_feed331wait" in   File 629" in , line """
  File 
 in 
, line wait" in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner331, line , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "  File wait  File 1045
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.pywait"
 in 231982""/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py"
" in   File "
, line   File wait in  in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py_bootstrap_inner", line   File 1002"
_feedrun231", line """
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py60 in /usr/local/python3.11.13/lib/python3.11/threading.py  File "

 in , line 60, line /usr/local/python3.11.13/lib/python3.11/threading.py, line   File " in _bootstrap""/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py  File   File _feed1045 in 982"60", line run
, line /usr/local/python3.11.13/lib/python3.11/threading.py"""
 in run in , line  in /usr/local/python3.11.13/lib/python3.11/threading.py60

1002"/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner
run629run" in   File Thread 0x in , line "60""
  File 
 in 
, line run"0000fff913fff120_bootstrap629, line  in , line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File wait  File 1002
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):

 in 982run1045""/usr/local/python3.11.13/lib/python3.11/threading.py"
" in   File "  File 
wait in 
 in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap", line "Thread 0x
run  File _bootstrap_inner982", line """
/usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/threading.py0000fff927fff120  File 
"
 in , line 1045, line /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line 1045" in "
 (most recent call first):
"  File /usr/local/python3.11.13/lib/python3.11/threading.py  File run1002 in 1045" in , line _bootstrap_inner, line Thread 0x  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py"""
 in _bootstrap_inner in , line _bootstrap_inner1045
3270000fff94bfff120"/usr/local/python3.11.13/lib/python3.11/threading.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap
_bootstrap_inner60
 in   File  in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"1045, line ""
  File 
 in   File _bootstrap_inner"wait  File ", line  in 60, line /usr/local/python3.11.13/lib/python3.11/threading.py
"  File run"
/usr/local/python3.11.13/lib/python3.11/threading.py
", line 1045_bootstrap_inner in 1002"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py327 in 
run in , line 0000fff943fff120"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "" in _bootstrap_inner  File 
_bootstrap1045 (most recent call first):
, line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line wait
"  File 
 in   File 1002, line /usr/local/python3.11.13/lib/python3.11/threading.py1002" in "327
  File /usr/local/python3.11.13/lib/python3.11/threading.py"
_bootstrap_inner" in 1002" in , line _bootstrap, line  in   File ""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap in , line _bootstrap1002
231wait"/usr/local/python3.11.13/lib/python3.11/threading.py, line "0000fff953fff120  File "
_bootstrap1045
 in 
 in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"1002, line  (most recent call first):
", line 

 in 
_bootstrapThread 0x_feed  File ", line  in 1045  File /usr/local/python3.11.13/lib/python3.11/threading.py327Thread 0x
_bootstrap_innerThread 0x
0000fff92bfef120
", line 1002_bootstrap in "" in 0000fff913fff120Thread 0x
0000fff943fff120
 (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231 in 
_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py, line wait (most recent call first):
0000fff93ffff120  File  (most recent call first):
Thread 0x  File "" in _bootstrap

"1002
  File  (most recent call first):
"  File 0000fff913fff120"/usr/local/python3.11.13/lib/python3.11/threading.py, line _feed
Thread 0x  File , line  in   File "  File /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"231

0000fff917fff120"327_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line  in   File Thread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py, line "", line 982_feed"0000fff94bfff120  File "wait
", line "1002, line /usr/local/python3.11.13/lib/python3.11/threading.py327 in 
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
", line 
Thread 0x, line 327, line  in 327" in run  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py1002  File 0000fff96bfff120231 in 327_bootstrap in , line wait
", line "" in " (most recent call first):
 in wait in 
wait327
  File /usr/local/python3.11.13/lib/python3.11/threading.py982/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File _feed
wait

 in   File "" in "327
""
  File 
Thread 0x  File wait"/usr/local/python3.11.13/lib/python3.11/threading.py, line run, line  in 
, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File 0000fff927fff120"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"982
327waitThread 0x231""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File ", line  in   File  in 
0000fff913fff120 in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "", line 1045run"wait  File  (most recent call first):
_feed327", line "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231 in 
/usr/local/python3.11.13/lib/python3.11/threading.py
"  File 
 in , line 231, line /usr/local/python3.11.13/lib/python3.11/threading.py231" in _bootstrap_inner  File "  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait982 in 231" in , line _feed
", line ""/usr/local/python3.11.13/lib/python3.11/threading.py"
 in _feed in , line _feed231
  File /usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File run
_feed327
 in   File "" in "231, line ""
  File 
 in   File _feed"/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap_inner, line  in 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "  File wait"
/usr/local/python3.11.13/lib/python3.11/threading.py"1045
231_feed in 982""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line  in   File  in 
wait in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line 1002_bootstrap_inner"_feed  File 
run231", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py982 in 
/usr/local/python3.11.13/lib/python3.11/threading.py
"  File 
 in , line 982, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py982" in _bootstrap  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py"  File _feed1045 in 982" in , line run
", line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
 in run in , line run982

/usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/threading.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner
run231
 in   File Thread 0x" in "982, line ""
  File 
 in   File run"0000fff91ffff120, line _bootstrap, line  in 231, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File _feed"
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
1002
982run in 1045""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File  in 
 in 
_feed in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "_bootstrapThread 0xrun  File 
_bootstrap_inner982", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff933fff120
"  File 
 in , line 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py1045" in "
 (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py"  File run1002 in 1045" in , line _bootstrap_inner, line Thread 0x  File ""/usr/local/python3.11.13/lib/python3.11/threading.py"
 in _bootstrap_inner in , line _bootstrap_inner1045
3270000fff95ffff120"/usr/local/python3.11.13/lib/python3.11/threading.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap
_bootstrap_inner982
 in   File  in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"1045, line ""
  File 
 in   File _bootstrap_inner"wait  File ", line  in 982, line /usr/local/python3.11.13/lib/python3.11/threading.py
"  File run"
/usr/local/python3.11.13/lib/python3.11/threading.py
", line 1045_bootstrap_inner in 1002"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py327 in 
run in , line 0000fff94ffff120"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "" in _bootstrap_inner  File 
_bootstrap1045 (most recent call first):
, line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line wait
"  File 
 in   File 1002, line /usr/local/python3.11.13/lib/python3.11/threading.py1002" in "327
  File /usr/local/python3.11.13/lib/python3.11/threading.py"
_bootstrap_inner" in 1002" in , line _bootstrap, line  in   File ""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap in , line _bootstrap1002
231wait"/usr/local/python3.11.13/lib/python3.11/threading.py, line "0000fff95ffff120  File "
_bootstrap1045
 in 
 in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"1002, line  (most recent call first):
", line 

 in 
_bootstrapThread 0x_feed  File ", line  in 1045  File /usr/local/python3.11.13/lib/python3.11/threading.py327Thread 0x
_bootstrap_innerThread 0x
0000fff92ffff120
", line 1002_bootstrap in "" in 0000fff91ffff120Thread 0x
0000fff94ffff120
 (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231 in 
_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py, line wait (most recent call first):
0000fff94bfff120  File  (most recent call first):
Thread 0x  File "" in _bootstrap

"1002
  File  (most recent call first):
"  File 0000fff91ffff120"/usr/local/python3.11.13/lib/python3.11/threading.py, line _feed
Thread 0x  File , line  in   File "  File /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"231

0000fff923fff120"327_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line  in   File Thread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py, line "", line 982_feed"0000fff95ffef120  File "wait
", line "1002, line /usr/local/python3.11.13/lib/python3.11/threading.py327 in 
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
", line 
Thread 0x, line 327, line  in 327" in run  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py1002  File 0000fff977fff120231 in 327_bootstrap in , line wait
", line "" in " (most recent call first):
 in wait in 
wait327
  File /usr/local/python3.11.13/lib/python3.11/threading.py982/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File _feed
wait

 in   File "" in "327
""
  File 
Thread 0x  File wait"/usr/local/python3.11.13/lib/python3.11/threading.py, line run, line  in 
, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File 0000fff933fff120"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"982
327waitThread 0x231""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File ", line  in   File  in 
0000fff91ffff120 in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "", line 1045run"wait  File  (most recent call first):
_feed327", line "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231 in 
/usr/local/python3.11.13/lib/python3.11/threading.py
"  File 
 in , line 231, line /usr/local/python3.11.13/lib/python3.11/threading.py231" in _bootstrap_inner  File "  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait982 in 231" in , line _feed
", line ""/usr/local/python3.11.13/lib/python3.11/threading.py"
 in _feed in , line _feed231
  File /usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File run
_feed327
 in   File "" in "231, line ""
  File 
 in   File _feed"/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap_inner, line  in 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "  File wait"
/usr/local/python3.11.13/lib/python3.11/threading.py"1045
231_feed in 982""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line  in   File  in 
wait in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line 1002_bootstrap_inner"_feed  File 
run231", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py982 in 
/usr/local/python3.11.13/lib/python3.11/threading.py
"  File 
 in , line 982, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py982" in _bootstrap  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py"  File _feed1045 in 982" in , line run
", line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
 in run in , line run982

/usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/threading.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner
run231
 in   File Thread 0x" in "982, line ""
  File 
 in   File run"0000fff92bfff120, line _bootstrap, line  in 231, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File _feed"
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
1002
982run in 1045""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File  in 
 in 
_feed in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "_bootstrapThread 0xrun  File 
_bootstrap_inner982", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff93ffff120
"  File 
 in , line 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py1045" in "
 (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py"  File run1002 in 1045" in , line _bootstrap_inner, line Thread 0x  File ""/usr/local/python3.11.13/lib/python3.11/threading.py"
 in _bootstrap_inner in , line _bootstrap_inner1045
3270000fff96bfef120"/usr/local/python3.11.13/lib/python3.11/threading.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap
_bootstrap_inner982
 in   File  in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"1045, line ""
  File 
 in   File _bootstrap_inner"wait  File ", line  in 982, line /usr/local/python3.11.13/lib/python3.11/threading.py
"  File run"
/usr/local/python3.11.13/lib/python3.11/threading.py
", line 1045_bootstrap_inner in 1002"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py327 in 
run in , line 0000fff95bfff120"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "", line  in _bootstrap_inner  File 
_bootstrap1045 (most recent call first):
, line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327wait
"  File 
 in   File 1002, line /usr/local/python3.11.13/lib/python3.11/threading.py1002" in " in 
  File /usr/local/python3.11.13/lib/python3.11/threading.py"
_bootstrap_inner" in 1002" in , line _bootstrap, line wait  File ""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap in , line _bootstrap1002
231
"/usr/local/python3.11.13/lib/python3.11/threading.py, line "0000fff96bfff120  File "
_bootstrap1045
 in 
 in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"1002, line  (most recent call first):
", line 

 in 
_bootstrapThread 0x_feed"", line  in 1045  File /usr/local/python3.11.13/lib/python3.11/threading.py327Thread 0x
_bootstrap_innerThread 0x
0000fff943fff120
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line 1002_bootstrap in "" in 0000fff92bfff120Thread 0x
0000fff95bfff120
 (most recent call first):
  File "231 in 
_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py, line wait (most recent call first):
0000fff957fff120  File  (most recent call first):
Thread 0x  File ", line  in _bootstrap

"1002
  File  (most recent call first):
"  File 0000fff92bfff120"/usr/local/python3.11.13/lib/python3.11/threading.py231_feed
Thread 0x  File , line  in   File "  File /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py" in 

0000fff92ffdf120"327_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line _feed  File Thread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py, line "", line 982
"0000fff963fff120  File "wait
", line "1002, line /usr/local/python3.11.13/lib/python3.11/threading.py327 in   File /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
", line 
Thread 0x, line 327, line  in 327" in run""  File /usr/local/python3.11.13/lib/python3.11/threading.py1002  File 0000fff980e5f120231 in 327_bootstrap in , line wait
/usr/local/python3.11.13/lib/python3.11/threading.py, line "" in " (most recent call first):
 in wait in 
wait327
  File "982/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File _feed
wait

 in   File ", line  in "327
""
  File 
Thread 0x  File wait"/usr/local/python3.11.13/lib/python3.11/threading.py982run, line  in 
, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File 0000fff93ffff120"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" in 
327waitThread 0x231""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File ", line run  File  in 
0000fff92bfff120 in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "", line 1045
"wait  File  (most recent call first):
_feed327", line "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231 in   File /usr/local/python3.11.13/lib/python3.11/threading.py
"  File 
 in , line 231, line /usr/local/python3.11.13/lib/python3.11/threading.py231" in _bootstrap_inner""  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait982 in 231" in , line _feed
/usr/local/python3.11.13/lib/python3.11/threading.py, line ""/usr/local/python3.11.13/lib/python3.11/threading.py"
 in _feed in , line _feed231
  File "1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File run
_feed327
 in   File ", line  in "231 in _feed
, line ""
  File 
 in   File _feed"/usr/local/python3.11.13/lib/python3.11/threading.py1045_bootstrap_inner, line   File 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "  File wait"
/usr/local/python3.11.13/lib/python3.11/threading.py" in 
231" in 982""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line _bootstrap_inner  File  in /usr/local/python3.11.13/lib/python3.11/threading.pywait in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line 1002
"_feed"
run231", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py982 in   File /usr/local/python3.11.13/lib/python3.11/threading.py
, line   File 
 in , line 982, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py982" in _bootstrap""  File 982"  File _feed1045 in 982" in , line run
/usr/local/python3.11.13/lib/python3.11/threading.py, line " in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
 in run in , line run982

"1002/usr/local/python3.11.13/lib/python3.11/threading.pyrun"/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner
run231
 in   File Thread 0x, line  in "
, line ""
  File 
 in   File run"0000fff937fff1201002_bootstrap, line   File 231, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "  File _feed"
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
 in 
982" in 1045""/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File _bootstrap
 in /usr/local/python3.11.13/lib/python3.11/threading.py_feed in , line /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line "
Thread 0xrun"
_bootstrap_inner982", line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff94bfff120
, line   File 
 in , line 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py1045" in "Thread 0x (most recent call first):
  File 1045"  File run1002 in 1045" in , line _bootstrap_inner, line 0000fff96ffff120  File " in /usr/local/python3.11.13/lib/python3.11/threading.py"
 in _bootstrap_inner in , line _bootstrap_inner1045
327 (most recent call first):
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner"/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap
_bootstrap_inner982
 in   File  in   File /usr/local/python3.11.13/lib/python3.11/threading.py"
, line ""
  File 
 in   File _bootstrap_inner"wait"", line   File 982, line /usr/local/python3.11.13/lib/python3.11/threading.py
"  File run"
/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py, line 1045" in 1002"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "  File "327 in /usr/local/python3.11.13/lib/python3.11/threading.pyrun in , line 0000fff967fff120"/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line ", line  in _bootstrap_inner"
_bootstrap1045 (most recent call first):
, line "", line /usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327wait
, line   File 
 in   File 1002, line /usr/local/python3.11.13/lib/python3.11/threading.py1002" in " in 
  File 1002"
_bootstrap_inner" in 1002" in , line _bootstrap, line wait  File " in /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap in , line _bootstrap1002
231
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap"0000fff977fff120  File "
_bootstrap1045
 in 
 in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
, line  (most recent call first):
", line 

 in 
_bootstrapThread 0x_feed"", line 
1045  File /usr/local/python3.11.13/lib/python3.11/threading.py327Thread 0x
_bootstrap_innerThread 0x
0000fff94ffef120
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line 1002Thread 0x in "" in 0000fff937fff120Thread 0x
0000fff967fff120
 (most recent call first):
  File "231 in 0000fff933fef120_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py, line wait (most recent call first):
0000fff963fff120  File  (most recent call first):
Thread 0x  File ", line  in _bootstrap (most recent call first):

"1002
  File  (most recent call first):
"  File 0000fff937fff120"/usr/local/python3.11.13/lib/python3.11/threading.py231_feed
  File   File , line  in   File "  File /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py" in 

""327_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line _feed  File Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line  in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py"", line 982
"0000fff96ce5f120""1002wait
"", line , line /usr/local/python3.11.13/lib/python3.11/threading.py327 in   File /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
, line , line  in 
Thread 0x, line , line 327327" in run""  File 3271002_bootstrap  File 0000fff984e6f120231327 in  in , line wait (most recent call first):

/usr/local/python3.11.13/lib/python3.11/threading.py, line " in  in 
" in  in waitwait327
  File   File "982/usr/local/python3.11.13/lib/python3.11/threading.pywait_bootstrap
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_feedwait

 in  in   File "", line "

Thread 0x"

  File   File waitrun"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py982, line   File 
0000fff94bfff120, line   File   File ""

/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"" in 327"Thread 0x (most recent call first):
231""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File   File ", line , line run in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py0000fff937fff120  File  in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"""", line 3271045
wait" (most recent call first):
"_feed"", line , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py231 in  in   File 
, line   File /usr/local/python3.11.13/lib/python3.11/threading.py
, line , line 231231"" in wait_bootstrap_inner"  File 231""  File 231982 in  in , line , line _feed

/usr/local/python3.11.13/lib/python3.11/threading.py" in /usr/local/python3.11.13/lib/python3.11/threading.py, line " in  in _feed_feed2311045
  File   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_feed"327/usr/local/python3.11.13/lib/python3.11/threading.py_feedrun

 in  in   File "", line "
, line  in "

  File   File _feed_bootstrap_inner"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py1045, line   File 327wait, line   File   File ""

/usr/local/python3.11.13/lib/python3.11/threading.py"" in 231" in 
982""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File   File ", line , line _bootstrap_inner in /usr/local/python3.11.13/lib/python3.11/threading.pywait  File  in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"""", line 2311002
_feed"
"run"", line , line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py982 in  in   File 
, line   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
, line , line 982982"" in _feed_bootstrap"  File 982""  File 9821045 in  in , line , line run

/usr/local/python3.11.13/lib/python3.11/threading.py" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line " in  in runrun9821002
  File 
"/usr/local/python3.11.13/lib/python3.11/threading.pyrun"231/usr/local/python3.11.13/lib/python3.11/threading.pyrun_bootstrap_inner

 in  in   File "Thread 0x, line "
, line  in "

  File   File run_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py0000fff943fff1201002, line   File 231_feed, line   File   File ""

/usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
 in 982" in 
1045""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File 
", line   File _bootstrap in /usr/local/python3.11.13/lib/python3.11/threading.py_feed  File  in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"""Thread 0x, line 982"
run"
"_bootstrap_inner"", line , line /usr/local/python3.11.13/lib/python3.11/threading.py0000fff957fff1201045 in /usr/local/python3.11.13/lib/python3.11/threading.py

, line   File /usr/local/python3.11.13/lib/python3.11/threading.py
, line , line 10451045" (most recent call first):
 in run"Thread 0x  File 1045""  File 10451002 in  in , line   File _bootstrap_inner
, line 0000fff97bfef120" in /usr/local/python3.11.13/lib/python3.11/threading.py, line " in  in _bootstrap_inner_bootstrap_inner1045"
  File 327 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner"982/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner_bootstrap

 in /usr/local/python3.11.13/lib/python3.11/threading.py  File " in   File "
, line  in "

  File   File _bootstrap_inner""/usr/local/python3.11.13/lib/python3.11/threading.pywait", line   File 982run, line   File 
""
, line /usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/threading.py1045" in 
1002"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File 327", line   File " in /usr/local/python3.11.13/lib/python3.11/threading.pyrun  File  in /usr/local/python3.11.13/lib/python3.11/threading.py0000fff973fff120""" in , line 1045", line _bootstrap_inner"
"_bootstrap" (most recent call first):
, line , line /usr/local/python3.11.13/lib/python3.11/threading.pywait1002 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327
, line   File /usr/local/python3.11.13/lib/python3.11/threading.py
, line   File 10021002"
 in _bootstrap_inner" in   File 1002""
1002" in  in , line   File _bootstrap
, line wait" in /usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_bootstrap1002"
  File 231
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap"10450000fff983fff120_bootstrap"

 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
" in   File "
, line  in  (most recent call first):

, line 

_bootstrap"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py_feed", line 
1045_bootstrap_inner  File 
327Thread 0xThread 0x
, line 0000fff953fff120"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py1002Thread 0x in 
"Thread 0x in 0000fff973fff1200000fff943fff120
231 (most recent call first):
, line   File " in 0000fff937fff120_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/threading.py0000fff96ffff120wait (most recent call first):
 (most recent call first):
Thread 0x in   File 1002", line _bootstrap (most recent call first):

"  File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py", line  (most recent call first):
"
, line 1002  File   File   File , line   File 0000fff943fff120327_feed in "" in "/usr/local/python3.11.13/lib/python3.11/threading.py"2311002
"  File  (most recent call first):
 in 
_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in  in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait  File 
""
", line "_feed_bootstrapThread 0x"/usr/local/python3.11.13/lib/python3.11/threading.py"
"
, line , line 
, line 982, line 

0000fff970e6f120, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x327327Thread 0x327 in 327  File 
 (most recent call first):
231, line """0000fff957fef120 in  in 0000fff997fff120 in run in "Thread 0x  File  in 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line  (most recent call first):
waitwait (most recent call first):
wait
wait/usr/local/python3.11.13/lib/python3.11/threading.py0000fff943fff120"_feed in 327"982  File 

  File 
  File 
" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py
wait in , line  in "  File   File "  File "  File , line   File "  File 
wait231run/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"/usr/local/python3.11.13/lib/python3.11/threading.py"982", line "  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in /usr/local/python3.11.13/lib/python3.11/threading.py327/usr/local/python3.11.13/lib/python3.11/threading.py"  File _feed  File , line "", line ", line "run" in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
"327, line , line 395, line 1045, line 
, line wait, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 231231 in 231 in 231  File 327
982, line """wait in  in _recv in _bootstrap_inner in " in   File  in 231, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
_feed_feed
_feed
_feed/usr/local/python3.11.13/lib/python3.11/threading.pywait"run in 231"1045  File 

  File 
  File 
"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
_feed in , line  in "  File   File "  File "  File , line   File "  File 
_feed982_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"/usr/local/python3.11.13/lib/python3.11/threading.py"1045", line "  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231/usr/local/python3.11.13/lib/python3.11/threading.py"  File run  File , line "", line ", line "_bootstrap_inner" in "/usr/local/python3.11.13/lib/python3.11/threading.py"
"231, line , line 430, line 1002, line 
, line _feed, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 982982 in 982 in 982  File 231
1045, line """_feed in  in _recv_bytes in _bootstrap in " in   File  in 982, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
runrun
run
run/usr/local/python3.11.13/lib/python3.11/threading.py_feed"_bootstrap_inner in 982"1002  File 

  File 


"
/usr/local/python3.11.13/lib/python3.11/threading.py
run in , line  in "  File   File "  File Thread 0x  File , line   File "  File 
run1045_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"0000fff94ffff120"1002", line "  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/threading.py982/usr/local/python3.11.13/lib/python3.11/threading.py"  File _bootstrap_inner
, line "", line "  File "_bootstrap" in "/usr/local/python3.11.13/lib/python3.11/threading.py"
Thread 0x982, line , line 250, line ", line 
, line run, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File 0000fff963fff120 in 10451045 in 1045/usr/local/python3.11.13/lib/python3.11/threading.py1045
982
1002, line "" (most recent call first):
run in  in recv in " in Thread 0x in   File  in 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py  File 
_bootstrap_inner_bootstrap_inner
_bootstrap_inner, line _bootstrap_inner0000fff97ffff120run"_bootstrap in 1045""  File 

  File 
327
 (most recent call first):

/usr/local/python3.11.13/lib/python3.11/threading.py
_bootstrap_inner in , line /usr/local/python3.11.13/lib/python3.11/threading.py"  File   File "  File  in   File   File   File "

_bootstrap_inner1002"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"wait""", line Thread 0x  File 
 in , line "/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py10450000fff97ffff120"  File _bootstrap327, line "", line "  File """ in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"
 in 1045, line , line 822, line ", line , line , line _bootstrap_inner  File "/usr/local/python3.11.13/lib/python3.11/threading.py
wait in 10021002 in 1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py10023271045
", line "Thread 0x
_bootstrap_inner in  in _callmethod in " in  in  in   File /usr/local/python3.11.13/lib/python3.11/threading.py1002, line 0000fff98ce5f120  File 
_bootstrap_bootstrap
_bootstrap, line _bootstrapwait_bootstrap_inner"" in 1002 (most recent call first):
"  File 

  File 
231


/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"

"
 in 
  File   File "327
_bootstrap""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0xThread 0x<string>Thread 0x_feedThread 0x"", line  in 

/usr/local/python3.11.13/lib/python3.11/threading.py, line "0000fff95ffff1200000fff97ffff120"0000fff978e5f120
0000fff94ffff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py1002waitThread 0x
"231, line  (most recent call first):
 (most recent call first):
, line  (most recent call first):
  File  (most recent call first):
"" in 
0000fff94bfff120Thread 0x, line  in 1002  File   File 2  File "  File , line , line _bootstrap  File  (most recent call first):
0000fff94ffff120327_feed in "" in "/usr/local/python3.11.13/lib/python3.11/threading.py"2311002
"  File  (most recent call first):
 in 
_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pyget/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in  in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait  File 
""
", line "_feed_bootstrapThread 0x"/usr/local/python3.11.13/lib/python3.11/threading.py"
"
, line , line   File , line 982, line 

0000fff983fff120327, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x327"327 in 327  File 
 (most recent call first):
 in 231, line """0000fff95bfff120 in /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py in run in "Thread 0x  File wait in 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line  (most recent call first):
wait"wait
wait/usr/local/python3.11.13/lib/python3.11/threading.py0000fff94ffff120"
_feed in 327"982  File 
, line 
  File 
" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File 
wait in , line  in "  File 68  File "  File , line   File ""  File 
wait231run/usr/local/python3.11.13/lib/python3.11/threading.py" in "/usr/local/python3.11.13/lib/python3.11/threading.py"982", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrun/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in /usr/local/python3.11.13/lib/python3.11/threading.py395"/usr/local/python3.11.13/lib/python3.11/threading.py"  File _feed  File , line "
", line "run" in , line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
"327, line   File , line 1045, line 
, line _recv231, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 231"231 in 231  File 327
 in 982, line """wait in /usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap_inner in " in   File _feed in 231, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
_feed"_feed
_feed/usr/local/python3.11.13/lib/python3.11/threading.pywait"
run in 231"1045  File 
, line 
  File 
"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File 
_feed in , line  in "  File 1045  File "  File , line   File ""  File 
_feed982_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" in "/usr/local/python3.11.13/lib/python3.11/threading.py"1045", line /usr/local/python3.11.13/lib/python3.11/threading.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py430"/usr/local/python3.11.13/lib/python3.11/threading.py"  File run  File , line "
", line "_bootstrap_inner" in , line "/usr/local/python3.11.13/lib/python3.11/threading.py"
"231, line   File , line 1002, line 
, line _recv_bytes982, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 982"982 in 982  File 231
 in 1045, line """_feed in /usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap in " in   File run in 982, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
run"run
run/usr/local/python3.11.13/lib/python3.11/threading.py_feed"
_bootstrap_inner in 982"1002  File 
, line 


"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File 
run in , line  in "  File 1002  File Thread 0x  File , line   File ""  File 
run1045_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py" in "0000fff958e5f120"1002", line /usr/local/python3.11.13/lib/python3.11/threading.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/threading.py250"/usr/local/python3.11.13/lib/python3.11/threading.py"  File _bootstrap_inner
, line "
"  File "_bootstrap" in , line "/usr/local/python3.11.13/lib/python3.11/threading.py"
Thread 0x982, line 
, line ", line 
, line recv1045, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File 0000fff96ce5f120 in 1045Thread 0x1045/usr/local/python3.11.13/lib/python3.11/threading.py1045
982
 in 1002, line "" (most recent call first):
run in 0000fff9abfff120 in " in Thread 0x in   File _bootstrap_inner in 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py  File 
_bootstrap_inner (most recent call first):
_bootstrap_inner, line _bootstrap_inner0000fff988e5f120run"
_bootstrap in 1045""  File 
  File 
327
 (most recent call first):

/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py  File 
_bootstrap_inner in , line /usr/local/python3.11.13/lib/python3.11/threading.py"  File "  File  in   File   File   File ""

_bootstrap_inner1002"/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py"wait""", line /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x  File 
 in , line "/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py822"0000fff988e5f120"  File _bootstrap327, line ", line "  File """ in , line  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"
 in 1045, line 331, line ", line , line , line _callmethod1002  File "/usr/local/python3.11.13/lib/python3.11/threading.py
wait in 1002 in 1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py10023271045
 in ", line "Thread 0x
_bootstrap_inner in wait in " in  in  in   File _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py1002, line 0000fff990e6f120  File 
_bootstrap
_bootstrap, line _bootstrapwait_bootstrap_inner"
" in 1002 (most recent call first):
"  File 
  File 
231


<string>
, line _bootstrap in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
"
 in 
  File   File "Thread 0x327
_bootstrap""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x_feedThread 0x"", line 0000fff968e5f120 in 

/usr/local/python3.11.13/lib/python3.11/threading.py, line "0000fff988e5f120"0000fff97ce6f120
0000fff958e5f120/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py2 (most recent call first):
waitThread 0x
"231, line  (most recent call first):
, line  (most recent call first):
  File  (most recent call first):
"" in   File 
0000fff954e5f120Thread 0x, line  in 1002  File 629  File "  File , line , line get"  File  (most recent call first):
0000fff958e5f120327_feed in " in "/usr/local/python3.11.13/lib/python3.11/threading.py"2311002
/usr/local/python3.11.13/lib/python3.11/threading.py"  File  (most recent call first):
 in 
_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.pywait/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in  in   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File wait  File 
"
", line "_feed_bootstrap", line "/usr/local/python3.11.13/lib/python3.11/threading.py"
"
, line   File , line 982, line 

/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py327, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x327"327 in 327  File 
" in 231, line """0000fff964e5f120 in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in run in "Thread 0x, line wait in 327, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line  (most recent call first):
wait"wait
wait/usr/local/python3.11.13/lib/python3.11/threading.py0000fff958e5f12068
_feed in 327"982  File 
, line 
  File 
" (most recent call first):
 in   File 
wait in , line  in "  File 60  File "  File , line   File run"  File 
wait231run/usr/local/python3.11.13/lib/python3.11/threading.py" in "/usr/local/python3.11.13/lib/python3.11/threading.py"982"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrun/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in /usr/local/python3.11.13/lib/python3.11/threading.py  File "/usr/local/python3.11.13/lib/python3.11/threading.py"  File _feed  File , line "
", line "run"", line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
"327, line   File , line 1045, line 
, line /usr/local/python3.11.13/lib/python3.11/threading.py231, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 231"231 in 231  File 327" in 982, line """wait in /usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap_inner in " in , line _feed in 231, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
_feed"_feed
_feed/usr/local/python3.11.13/lib/python3.11/threading.pywait1045
run in 231"1045  File 
, line 
  File 
"
 in   File 
_feed in , line  in "  File 1045  File "  File , line   File _bootstrap_inner"  File 
_feed982_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" in "/usr/local/python3.11.13/lib/python3.11/threading.py"1045"
/usr/local/python3.11.13/lib/python3.11/threading.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "/usr/local/python3.11.13/lib/python3.11/threading.py"  File run  File , line "
", line "_bootstrap_inner"", line "/usr/local/python3.11.13/lib/python3.11/threading.py"
"231, line   File , line 1002, line 
, line /usr/local/python3.11.13/lib/python3.11/threading.py982, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in 982"982 in 982  File 231" in 1045, line """_feed in /usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap in " in , line run in 982, line /usr/local/python3.11.13/lib/python3.11/threading.py, line 
run"run
run/usr/local/python3.11.13/lib/python3.11/threading.py_feed1002
_bootstrap_inner in 982"1002  File 
, line 


"
 in   File 
run in , line  in "  File 1002  File Thread 0x  File , line   File _bootstrap"  File 
run1045_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py" in "0000fff95ce6f120"1002"
/usr/local/python3.11.13/lib/python3.11/threading.py"  File 
 in 
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/threading.py
"/usr/local/python3.11.13/lib/python3.11/threading.py"  File _bootstrap_inner
, line "
"  File "_bootstrap"Thread 0x, line "/usr/local/python3.11.13/lib/python3.11/threading.py"
Thread 0x982, line 
, line ", line 
, line 0000fff997fff1201045, line "/usr/local/python3.11.13/lib/python3.11/threading.py  File 0000fff970e6f120 in 1045Thread 0x1045/usr/local/python3.11.13/lib/python3.11/threading.py1045
982 (most recent call first):
 in 1002, line "" (most recent call first):
run in 0000fffce889f120 in " in Thread 0x in   File _bootstrap_inner in 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py  File 
_bootstrap_inner (most recent call first):
_bootstrap_inner, line _bootstrap_inner0000fff98ce6f120run  File "
_bootstrap in 1045""  File 

327
 (most recent call first):

"/usr/local/python3.11.13/lib/python3.11/threading.py  File 
_bootstrap_inner in , line /usr/local/python3.11.13/lib/python3.11/threading.py"  File   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap in   File   File   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py""

_bootstrap_inner1002"/usr/local/python3.11.13/lib/python3.11/threading.py"
wait"""", line /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x  File 
 in , line "/usr/local/python3.11.13/lib/python3.11/threading.py

/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py, line 3310000fff98ce6f120"  File _bootstrap327, line "Thread 0x  File "", line "61 in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"
 in 1045, line 0000fff98ffff120", line , line 1002, line  in wait  File "/usr/local/python3.11.13/lib/python3.11/threading.py
wait in 1002 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py1002327 in 1045_recv_msg
", line "Thread 0x
_bootstrap_inner in   File " in  in 1002_bootstrap in 
  File /usr/local/python3.11.13/lib/python3.11/threading.py, line 0000fff9a3fff120  File 
_bootstrap", line _bootstrapwait in 
_bootstrap_inner  File ""1002 (most recent call first):
"  File 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py231

_bootstrap

"/usr/local/python3.11.13/lib/python3.11/threading.py, line  in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_bootstrap"
" in 
  File 
Thread 0x  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"327""
/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x, line _feedThread 0x"
0000fff96ce6f120"", line  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line 
"0000fff98ce6f120395
0000fff95ce6f120/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyThread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py, line 629wait"231Thread 0x, line  (most recent call first):
 in   File  (most recent call first):
"0000fff958e6f120  File "195 in 
, line  in 0000fff95ce6f1201002_recv"  File   File , line  (most recent call first):
", line  in wait  File 395_feed (most recent call first):
 in 
/usr/local/python3.11.13/lib/python3.11/threading.py""231  File /usr/local/python3.11.13/lib/python3.11/threading.py1002_read_thread in 
"
  File _bootstrap  File "/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in "" in 
_recv  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "
", line ""_feed/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap  File 
"""/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py982, line , line 
"327
"  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line /usr/local/python3.11.13/lib/python3.11/threading.py"Thread 0x" in 327327  File , line  in 
"/usr/local/python3.11.13/lib/python3.11/threading.py"231", line 0000fff968e6f120, line run in  in "327waitThread 0x, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in , line 327 (most recent call first):
430wait
wait/usr/local/python3.11.13/lib/python3.11/threading.py in 
0000fff95ce6f12060, line "_feed982 in   File  in 
  File 
"wait  File  (most recent call first):
 in 982, line 
 in wait"_recv_bytes  File "  File , line 
"  File run in 430  File run
/usr/local/python3.11.13/lib/python3.11/threading.py
"/usr/local/python3.11.13/lib/python3.11/threading.py"982  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"
  File run in "
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in ""/usr/local/python3.11.13/lib/python3.11/threading.py  File "
_recv_bytes/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line ", line "run/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File 
""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327, line 1045, line 
"231, line /usr/local/python3.11.13/lib/python3.11/threading.py""  File , line /usr/local/python3.11.13/lib/python3.11/threading.py" in 231 in 231  File , line  in 327", line /usr/local/python3.11.13/lib/python3.11/threading.py"982", line wait in _feed
  File _bootstrap_inner in "231_feed in , line 250"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in , line 231
"
_feed/usr/local/python3.11.13/lib/python3.11/threading.py in 
wait1045 in , line "run1045 in   File /usr/local/python3.11.13/lib/python3.11/threading.py  File 
_feed"  File 
 in recv1045, line 
 in _feed"""  File 
, line "  File _bootstrap_inner
 in 250  File _bootstrap_inner
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line /usr/local/python3.11.13/lib/python3.11/threading.py"  File 1045/usr/local/python3.11.13/lib/python3.11/threading.py
  File _bootstrap_inner in "
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"982"/usr/local/python3.11.13/lib/python3.11/threading.py" in "  File "
recv/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line  in , line "/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py  File 
""/usr/local/python3.11.13/lib/python3.11/threading.py, line 231run1002, line "
982/usr/local/python3.11.13/lib/python3.11/threading.py""  File , line /usr/local/python3.11.13/lib/python3.11/threading.py"231 in 
 in 982, line _feed  File  in ", line /usr/local/python3.11.13/lib/python3.11/threading.py"1045", line  in   File _bootstrap in 982
"run, line 822""/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py in , line 982_feed
run in   File /usr/local/python3.11.13/lib/python3.11/threading.py
1002 in , line /usr/local/python3.11.13/lib/python3.11/threading.py"_bootstrap_inner1002 in 


run""  File  in _callmethod", line 1002
 in run  File Thread 0x  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, line "_bootstrap
, line 822 in   File _bootstrap
"0000fff96ffff120"  File "1002/usr/local/python3.11.13/lib/python3.11/threading.py
  File 1045 in _bootstrap"  File /usr/local/python3.11.13/lib/python3.11/threading.py
 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py", line  in "
" in _callmethod
/usr/local/python3.11.13/lib/python3.11/threading.py""
  File "/usr/local/python3.11.13/lib/python3.11/threading.py982_bootstrap, line Thread 0x<string>_bootstrap_inner

"/usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x", line " in 
10450000fffcd63ef120"
  File Thread 0x, line "9820000fff983fff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py1045, line run
 in  (most recent call first):
, line   File "0000ffffa7dbe8401002, line  in  (most recent call first):
" in  in 1045
Thread 0x_bootstrap_inner2"<string>  File  (most recent call first):
1045run  File , line _bootstrap_inner_bootstrap in   File 0000fff99ffff120
 in /usr/local/python3.11.13/lib/python3.11/threading.py""  File  in 
"395

_bootstrap_inner" (most recent call first):
  File get", line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in   File 

/usr/local/python3.11.13/lib/python3.11/threading.py  File "
, line 2"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
""_recv"Thread 0x  File ""/usr/local/python3.11.13/lib/python3.11/threading.py  File 1002 in , line "  File /usr/local/python3.11.13/lib/python3.11/threading.py, line 
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff99ffff120", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"" in get61, line ""395  File " (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py1045", line /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py_bootstrap
 in 358/usr/local/python3.11.13/lib/python3.11/threading.py, line  in ", line   File " in , line 1002"
  File _recv_msg in "1045_recv/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py1002", line _bootstrap_inner395 in , line 
"
get_current_stream, line  in 
" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py1002
 in _bootstrap68 in runThread 0x/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py  File 
1002_bootstrap_inner  File , line _bootstrap" in   File _recv

0000fff96ffff120""  File  in 
"430
, line _bootstrap"

  File  (most recent call first):
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"_bootstrap  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in 
395
/usr/local/python3.11.13/lib/python3.11/threading.py  File Thread 0x"  File 68"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
""_recv_bytesThread 0x in 
""0000fff97ffff120/usr/local/python3.11.13/lib/python3.11/threading.py" in , line "
/usr/local/python3.11.13/lib/python3.11/threading.py, line 
0000fff99ffff120_recvThread 0x, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py (most recent call first):
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pyrun195, line Thread 0x"430  File  (most recent call first):

0000fff96bfff1201002"  File , line "
 in 5920000fff96ffff120, line  in "  File   File  (most recent call first):
 in , line "1045, line   File _read_thread in  (most recent call first):
1002_recv_bytes/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py""  File _bootstrap430/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in 395"
run  File  in 
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"
 in "_bootstrap_inner in /usr/local/python3.11.13/lib/python3.11/threading.py  File 
"_bootstrap  File , line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
_recv_bytes, line 
_recv""  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
"250, line , line "Thread 0x
395  File 
, line /usr/local/python3.11.13/lib/python3.11/threading.py""
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in 3954300000fff97bfff120  File , line  in "  File 1045"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py, line Thread 0x"recv in  in  (most recent call first):
"395_recv/usr/local/python3.11.13/lib/python3.11/threading.py" in , line "3950000fff96ffff120, line 
_recv_recv_bytes  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in 
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py_bootstrap_inner982, line  in  (most recent call first):
250  File 

""_recv  File , line "
 in 773_recv  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line 
"1002, line   File run in 
"recv/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"""250  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in 430"
warmup  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line  in ""_bootstrap in /usr/local/python3.11.13/lib/python3.11/threading.py  File 
""  File , line ""395recv/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line 
_recv_bytes""  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line "822, line , line  in 
"430

, line /usr/local/python3.11.13/lib/python3.11/threading.py""395/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py in 430250_recv  File , line  in Thread 0x  File 1002"/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py, line  in "_callmethod in  in 
"430_recv_bytes0000fff9a3fff120" in , line "430_recv, line 
_recv_bytesrecv  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py in 
 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py_bootstrap1045, line  in 
822  File 

""_recv_bytes  File   File "
 in 115_recv_bytes  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line 
"", line 
_bootstrap_inner in 
"_callmethod<string>"""822  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/threading.py250Thread 0x
add_rmsnorm_bias
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py", line 53 in _rmsnorm_forward_oot
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py", line 67 in forward
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784 in _call_impl
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773 in _wrapped_call_impl  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, line  in """ in 0000fff9b7fff120  File 
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py", line ""  File , line ""430_callmethod/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line , line recv (most recent call first):
"96/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line "2, line , line  in 
"250331
  File /usr/local/python3.11.13/lib/python3.11/threading.py in "430<string> in 250822_recv_bytes  File , line  in  in   File ""forward, line  in "get in  in 
"250recvwait"/usr/local/python3.11.13/lib/python3.11/threading.py, line 
250_recv_bytes, line 
recv_callmethod  File <string> in 

/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"1002  File  in 
2  File 

""recv  File   File ", line  in "recv  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line 
"", line 331_bootstrap/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"get/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py"""2  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py/usr/local/python3.11.13/lib/python3.11/threading.py822 in 
"  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py<string>, line  in """ in wait
, line ""  File , line ""250get/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, line , line _callmethod
Thread 0x1784/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, line "68, line , line  in 
"822629
  File 0000ffff95903840 in "250/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py in 8222recv  File , line  in  in   File " (most recent call first):
_call_impl, line  in "run in  in 
"822_callmethodwait"/usr/local/python3.11.13/lib/python3.11/threading.py  File 
822recv, line 
_callmethodget  File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py in 

<string>""  File  in 
68  File 

""_callmethod  File   File ", line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py"_callmethod  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, line 
"", line 629"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"run/usr/local/python3.11.13/lib/python3.11/threading.py"""68  File <string>/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py2 in , line "  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py
"<string>/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, line  in """ in wait358, line ""  File , line ""822run<string>, line , line get
 in 1773<string>, line "1045, line , line  in 
"260
  File get_current_stream in "822/usr/local/python3.11.13/lib/python3.11/threading.py in 268_callmethod  File , line  in  in   File "
_wrapped_call_impl, line  in "_bootstrap_inner in  in 
"2getrun"/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py  File 
2_callmethod, line 
getrun  File /usr/local/python3.11.13/lib/python3.11/threading.py in 

/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py""  File  in 
1045  File 

""get  File   File ", line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py"get  File  in "  File   File <string>, line 
"", line 60"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py
"_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py"""1045  File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py/usr/local/python3.11.13/lib/python3.11/threading.py68 in , line "  File <string>
"/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py/usr/local/python3.11.13/lib/python3.11/threading.py, line  in """ in run592, line ""  File , line ""2_bootstrap_inner/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, line , line 1045run
 in 170/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, line "1002, line , line  in 
"68 in 
  File run in "2/usr/local/python3.11.13/lib/python3.11/threading.py in 681045get  File , line  in _bootstrap_inner  File "
forward, line  in "_bootstrap in  in 
"68run
"/usr/local/python3.11.13/lib/python3.11/threading.py  File 
68get, line 
run_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/threading.py in 
  File /usr/local/python3.11.13/lib/python3.11/threading.py""  File  in 
1002


""run  File "", line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py"run  File  in Thread 0x  File   File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, line 
"/usr/local/python3.11.13/lib/python3.11/threading.py, line 1045"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"_bootstrap0000fff983fff120"""1002  File /usr/local/python3.11.13/lib/python3.11/threading.py"1045 in , line "  File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py
 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line  in "", line  in _bootstrap_inner773, line ""
  File ""68_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py, line 1002_bootstrap_inner
 in 1784/usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x", line , line  in 
"1045 in 
  File warmup in "680000fff997fff120/usr/local/python3.11.13/lib/python3.11/threading.py10451002run
, line  in _bootstrap  File "
_call_impl, line  in  (most recent call first):
" in  in 
Thread 0x1045_bootstrap_inner
"/usr/local/python3.11.13/lib/python3.11/threading.py  File 
1045run  File , line _bootstrap_inner_bootstrap  File 0000fff9b3fff120 in 

/usr/local/python3.11.13/lib/python3.11/threading.py""  File  in 
"331

" (most recent call first):
_bootstrap_inner  File Thread 0x", line /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py"_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/threading.py in   File 
/usr/local/python3.11.13/lib/python3.11/threading.py  File 
"0000fffce065f120, line 1002"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
""wait"Thread 0x""  File /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
1002 in , line "  File /usr/local/python3.11.13/lib/python3.11/threading.py, line 
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff9b3fff120, line /usr/local/python3.11.13/lib/python3.11/threading.py"" in _bootstrap115  File , line ""331  File " (most recent call first):
1045"/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap
 in "1773/usr/local/python3.11.13/lib/python3.11/threading.py, line  in ", line   File  in , line "1002

add_rmsnorm_bias/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in "1045wait/usr/local/python3.11.13/lib/python3.11/threading.py1002"_bootstrap_inner331, line  in 
Thread 0x
"_wrapped_call_impl, line  in 
" in /usr/local/python3.11.13/lib/python3.11/threading.py
 in 1002_bootstrapThread 0x0000fffcf31bf120  File , line 
1002_bootstrap_inner  File , line _bootstrap"  File wait in 
0000fff983fff120 (most recent call first):
"61  File  in 
"629
, line "
_bootstrap
 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py in "  File _bootstrap  File /usr/local/python3.11.13/lib/python3.11/threading.py in 
331/usr/local/python3.11.13/lib/python3.11/threading.py  File 
Thread 0x  File "_recv_msg/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py"
""waitThread 0x in ""
0000fff993fff120", line 53 in 
"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py
/usr/local/python3.11.13/lib/python3.11/threading.py, line 
0000fff9b3fff120wait, line /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py_rmsnorm_forward_oot  File , line "Thread 0x"629  File  (most recent call first):

1002"0000fff97ffff120  File "
"469, line 0000fff983fff120, line  in "  File   File  in , line  (most recent call first):
", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in 61 (most recent call first):
1002wait/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py""_bootstrap629  File /usr/local/python3.11.13/lib/python3.11/threading.py331""forward in   File  in 
"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py
 in "" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py, line 
_recv_msg"_bootstrap  File , line ""
wait/usr/local/python3.11.13/lib/python3.11/threading.py, line wait"195  File 
/usr/local/python3.11.13/lib/python3.11/threading.py
"60, line , line Thread 0x
"331
, line  in "  File "
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in 3316290000fff98ffff120  File , line  in   File 67_read_thread/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line Thread 0x"run in  in  (most recent call first):
"331wait" in 
"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py3310000fff983fff120, line 
waitwait  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in 
/usr/local/python3.11.13/lib/python3.11/threading.pyforward  File , line " in  (most recent call first):
60  File 

""wait  File "
"120, line wait  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/threading.py, line 
", line   File /usr/local/python3.11.13/lib/python3.11/threading.py in 195
"run/usr/local/python3.11.13/lib/python3.11/threading.py"""60  File /usr/local/python3.11.13/lib/python3.11/threading.py629""decorate_context in   File /usr/local/python3.11.13/lib/python3.11/threading.py
"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line  in "" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line 
_read_thread""  File , line ""331run/usr/local/python3.11.13/lib/python3.11/threading.py, line wait"982  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, line "1045, line , line  in 
"629
, line  in "  File "331/usr/local/python3.11.13/lib/python3.11/threading.py in 62960wait  File , line  in   File 1784run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line  in "_bootstrap_inner in  in 
"629wait" in 
"/usr/local/python3.11.13/lib/python3.11/threading.py629wait, line 
waitrun  File /usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py_call_impl  File , line " in 
1045  File 

""wait  File "
"349, line wait  File  in "  File   File /usr/local/python3.11.13/lib/python3.11/threading.py, line 
", line   File /usr/local/python3.11.13/lib/python3.11/threading.py in 982
"_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py"""1045  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py60""run_once in   File /usr/local/python3.11.13/lib/python3.11/threading.py
"/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py/usr/local/python3.11.13/lib/python3.11/threading.py, line  in "" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line 
run""  File , line ""629_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line run"1045  File 
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line "1002, line , line  in 
"60
, line  in "  File "629/usr/local/python3.11.13/lib/python3.11/threading.py in 601045wait  File , line  in   File 1773_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py", line  in "_bootstrap in  in 
"60run" in 
"/usr/local/python3.11.13/lib/python3.11/threading.py60wait, line 
run_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/threading.py_wrapped_call_impl  File , line " in 
1002


""run  File "
"47, line run  File  in Thread 0x  File   File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py, line 
", line   File /usr/local/python3.11.13/lib/python3.11/threading.py in 1045
"_bootstrap0000fffcc208f120"""1002  File /usr/local/python3.11.13/lib/python3.11/threading.py1045""_capture_init in   File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py
 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line  in "" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line 
_bootstrap_inner""
""60  File _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap_inner"1002  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x, line , line  in "
"1045
, line  in "  File "600000fffcd548f12010451002run/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py
, line  in   File 96_bootstrap/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py", line  in  (most recent call first):
 in  in 
"Thread 0x1045_bootstrap_inner" in 
"/usr/local/python3.11.13/lib/python3.11/threading.py1045run_bootstrap_inner_bootstrap  File , line   File 0000fffcef97f120 in 
/usr/local/python3.11.13/lib/python3.11/threading.pyforward
, line " in 


"61" (most recent call first):
_bootstrap_inner  File "
Thread 0x361, line _bootstrap_inner  File   File 
/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py  File 
", line   File 0000ffff9fbe7840 in 1002
""Thread 0x"_recv_msg""  File /usr/local/python3.11.13/lib/python3.11/threading.py1002" (most recent call first):
capture_one_batch_size in   File /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py0000fffcf7c2f120, line 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File 
_bootstrap""" (most recent call first):
1045  File 61"/usr/local/python3.11.13/lib/python3.11/threading.py, line _bootstrap""  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, line , line  in "  File  in , line "1002
, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py"
"10451002_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"_recv_msg61, line  in 
1784"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.pyThread 0x, line  in  in 
"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py
 in 1002_bootstrapThread 0x in , line "0000ffffb26e28401002_bootstrap_inner_bootstrap  File , line "  File _recv_msg in 
0000fffcc1ddf120_call_impl358, line  (most recent call first):
 in 

"195, line "
_bootstrap
 (most recent call first):

 in 500  File _bootstrap  File 
/usr/local/python3.11.13/lib/python3.11/threading.py in 61/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py  File 
Thread 0x  File get_current_stream in   File "
"Thread 0x"_read_thread in ""
0000fffcdc06f120"
_capture_one_stream"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
/usr/local/python3.11.13/lib/python3.11/threading.py0000fffcf228f120, line 
_recv_msg, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.pyThread 0x (most recent call first):
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py"Thread 0x" (most recent call first):
1002  File 
195"0000fffcbca5f120""  File   File ", line 0000fffcbfb9f120, line  in "  File   File  in , line  (most recent call first):
, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py"", line 358 (most recent call first):
1002_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py""_read_thread1951773"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py61 in  in 
"  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py
 in  in , line """ in get_current_stream_bootstrap
, line """  File _read_thread_wrapped_call_impl592/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line , line _recv_msg

Thread 0x982/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line , line "

 in "51361
  File 
0000fffcd5a3f120 in "19561/usr/local/python3.11.13/lib/python3.11/threading.py  File   File run, line  in  in   File "Thread 0x (most recent call first):
run, line  in  in """
61capture_recv_msg"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py0000fffcbf98f120
61_read_thread  File _recv_msg, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py  File  in 

/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py" (most recent call first):
  File  in 
"
982"""_recv_msg  File   File ", line "_recv_msg  File   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py  File  in , line , line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
"", line 592/usr/local/python3.11.13/lib/python3.11/threading.py
""""run982170"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py195 in "  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py
 in  in , line """ in run, line """61"  File runforward773/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line , line _read_thread
1045/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line , line  in , line "

 in "229195
  File  in "61982_recv_msg195/usr/local/python3.11.13/lib/python3.11/threading.py  File   File warmup, line  in  in   File "_bootstrap_inner, line  in  in 
 in """
195capture_read_thread"/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
195_recv_msgrun  File _read_thread, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File  in 

/usr/local/python3.11.13/lib/python3.11/threading.py"  File  in 

"
1045"""_read_thread  File   File ", line "_read_thread  File   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py  File  in , line , line /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
"", line 773/usr/local/python3.11.13/lib/python3.11/threading.py
""""_bootstrap_inner10451784"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py/usr/local/python3.11.13/lib/python3.11/threading.py982 in "  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py
 in  in , line """ in warmup, line """195"  File _bootstrap_inner_call_impl115/usr/local/python3.11.13/lib/python3.11/threading.py, line , line run
1002/usr/local/python3.11.13/lib/python3.11/threading.py, line , line  in , line "

 in "181982
  File  in "1951045_read_thread982/usr/local/python3.11.13/lib/python3.11/threading.py  File   File add_rmsnorm_bias, line  in  in   File "_bootstrap, line  in  in 
 in """
982__init__run"/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
982_read_thread_bootstrap_inner  File run, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File  in 

/usr/local/python3.11.13/lib/python3.11/threading.py"
 in 

"
1002"""run  File   File ", line Thread 0xrun  File   File /usr/local/python3.11.13/lib/python3.11/threading.py  File  in , line , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py
"", line 1150000ffff815d7840
""""_bootstrap10021773"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py/usr/local/python3.11.13/lib/python3.11/threading.py1045 in  (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py
 in  in , line """ in add_rmsnorm_bias  File """982"
_bootstrap_wrapped_call_impl53/usr/local/python3.11.13/lib/python3.11/threading.py, line , line _bootstrap_inner
"/usr/local/python3.11.13/lib/python3.11/threading.py, line , line  in , line Thread 0x

 in "351045
  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py"9821002 in _bootstrap

Thread 0x0000ffffb715f840run10450000ffff949d0840
  File _rmsnorm_forward_oot, line  in  in   File "", line  in  (most recent call first):

 in  (most recent call first):
Thread 0x"
1045__init___bootstrap_inner"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py, line 1045run  File   File _bootstrap_inner  File 0000ffffaee8f840/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py  File  in 

/usr/local/python3.11.13/lib/python3.11/threading.py"358 in 
""
" (most recent call first):
""_bootstrap_inner  File   File ", line  in _bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py
"", line 53get_current_stream
""""""469"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py/usr/local/python3.11.13/lib/python3.11/threading.py1002 in 
  File /usr/local/python3.11.13/lib/python3.11/threading.py, line , line /usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py in , line """ in _rmsnorm_forward_oot  File ""3581045"358"forward67/usr/local/python3.11.13/lib/python3.11/threading.py, line , line _bootstrap
"/usr/local/python3.11.13/lib/python3.11/threading.py, line  in  in , line  in , line 
 in "2611002
  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py"1045get_current_stream_bootstrap_inner1002get_current_stream358  File forward, line  in  in 
"", line  in 

 in 
 in "
1002init_cuda_graphs_bootstrapThread 0x/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py, line 1002_bootstrap_inner  File   File _bootstrap  File get_current_stream/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py  File  in 

0000ffff81370840"592 in 
""
"
""_bootstrap  File 
 (most recent call first):
, line  in _bootstrap  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"Thread 0x  File 67run
"""Thread 0x""120"
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py0000ffff9b58d840" in 

/usr/local/python3.11.13/lib/python3.11/threading.py, line , line 0000ffffb179d840, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py in , line Thread 0x" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.pyforward  File Thread 0x"5921002 (most recent call first):
592"decorate_context17840000ffff7c078840, line   File "
"0000ffff7f0c9840, line  in  in   File  in , line 
 in  (most recent call first):
148", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py (most recent call first):
1002run_bootstrap"run592  File _call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py358""  File  in 

/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
 in "
"__init__" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line "_bootstrap  File 
"  File run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
, line get_current_stream"773/usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
"Thread 0x, line "
"""  File 358
, line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py0000ffff94f4f840358/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in   File 1784warmup, line Thread 0x" (most recent call first):
 in ""349"358/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.pyget_current_stream" in 
3580000ffff7eed4840, line   File get_current_stream, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py_call_impl  File  in  (most recent call first):
773"
773"run_once1773get_current_stream, line   File "
"get_current_stream  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py  File  in , line 
 in 
580", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
"warmup""warmup773  File _wrapped_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py592""  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/backends/ascend/driver.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
 in "
"__init__" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line ""  File 358"  File warmup/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
, line run"115/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py, line " in , line "
"""  File 592
, line  in "358/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.pyget_current_stream592/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line " in   File 1773add_rmsnorm_bias, line  in "
 in ""47"592/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pyrun" in 
592get_current_stream, line   File run, line /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py_wrapped_call_impl  File  in 
115"
115"_capture_init96run, line   File "
"run  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py  File  in , line 
 in 
269", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py
"add_rmsnorm_bias""add_rmsnorm_bias115  File forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py773""  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
 in "
"_create_eagle_worker" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line ""  File 592"  File add_rmsnorm_bias/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
, line warmup"53/usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py, line " in , line "
"""  File 773
, line  in "592/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.pyrun773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in   File 96_rmsnorm_forward_oot, line  in "
 in ""361"773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pywarmup" in 
773run, line   File warmup, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.pyforward  File  in 
53"
53"capture_one_batch_size1784warmup, line   File "
"warmup  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py  File  in , line 
 in 
197", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py
"_rmsnorm_forward_oot""_rmsnorm_forward_oot53  File _call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py115""  File /usr/local/python3.11.13/lib/python3.11/site-packages/triton/runtime/jit.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
 in "
"_factory" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line ""  File 773"  File _rmsnorm_forward_oot/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
, line add_rmsnorm_bias"67/usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py, line " in , line "
"""  File 115
, line  in "773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.pywarmup115/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in   File 1784forward, line  in "
 in ""500"115/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pyadd_rmsnorm_bias" in 
115warmup, line   File add_rmsnorm_bias, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py_call_impl  File  in 
67"
67"_capture_one_stream1773add_rmsnorm_bias, line   File "
"add_rmsnorm_bias  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py  File  in , line 
 in 
179", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"forward""forward67  File _wrapped_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py53""  File /usr/local/python3.11.13/lib/python3.11/site-packages/sgl_kernel_npu/norm/add_rmsnorm_bias.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py
 in "
"create_draft_worker" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line ""  File 115"  File forward/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py
, line _rmsnorm_forward_oot"1784/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py, line " in , line "
"""  File 53
, line  in "115/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyadd_rmsnorm_bias53/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line " in   File 1773_call_impl, line  in "
 in ""513"53/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_rmsnorm_forward_oot" in 
53add_rmsnorm_bias, line   File _rmsnorm_forward_oot, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py_wrapped_call_impl  File  in 
1784"
1784"capture170_rmsnorm_forward_oot, line   File "
"_rmsnorm_forward_oot  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py  File  in , line 
 in 
514", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"_call_impl""_call_impl1784  File forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py67""  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/quantization/modelslim.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py
 in "
"init_model_worker" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line ""  File 53"  File _call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py
, line forward"1773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py, line " in , line "
"""  File 67
, line  in "53/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_rmsnorm_forward_oot67/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in   File 170_wrapped_call_impl, line  in "
 in ""229"67/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyforward" in 
67_rmsnorm_forward_oot, line   File forward, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in , line  in "
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyforward  File  in 
1773"
1773"capture1784forward, line   File "
"forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py  File  in , line 
 in 
315", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py
"_wrapped_call_impl""_wrapped_call_impl1773  File _call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1784""  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/custom_op.py
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
 in "
__init__"" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line ""  File 67"  File _wrapped_call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line _call_impl"96/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in , line "
""  File "1784
, line  in "67/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.pyforward1784/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py", line  in   File 1784forward, line  in "
 in ""181"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py1784_call_impl" in 
1784forward, line   File _call_impl
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_call_impl  File  in 
96"  File 96"__init__, line _call_impl1773  File "
"_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line 
2828
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"forward"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyforward96  File  in   File _wrapped_call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1773""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in "run_scheduler_process"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line ""  File 1784, line   File forward/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line _wrapped_call_impl"1784/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in 1773"
"  File ""1773
, line  in "1784/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line ", line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py in   File 1773_call_impl, line  in "
_wrapped_call_impl""35/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py1773"_wrapped_call_impl" in 
1773_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py_wrapped_call_impl  File  in 
1784"  File 1784"__init__, line _wrapped_call_impl469  File "
"_wrapped_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line 
108
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"_call_impl"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py_call_impl1784  File  in   File forward/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py96""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in "run"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py, line ""  File 1773, line   File _call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py  File , line forward"1773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line " in 96"
"  File ""96
, line  in "1773/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_wrapped_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line ", line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py in   File 469_wrapped_call_impl, line  in "
forward""261/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py96"forward" in 
96_wrapped_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyforward  File  in 
1773"  File 1773"init_cuda_graphs, line forward120  File "
"forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py" in , line 
314
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py
"_wrapped_call_impl"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_wrapped_call_impl1773  File  in   File decorate_context/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1784""  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py
, line "
 in "_bootstrap"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py, line ""  File 96, line   File _wrapped_call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line _call_impl"170/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in 1784"
"  File ""1784
, line  in "96/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.pyforward in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py  File , line ", line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in   File 120forward, line  in "
_call_impl""148/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py1784"_call_impl" in 
1784forward, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pydecorate_context  File  in 
170"  File 170"__init__, line _call_impl349  File "
"_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line 
135
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"forward"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyforward170  File  in   File run_once/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1773""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in "_main"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line ""  File 1784, line   File forward/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line _wrapped_call_impl"1784/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in 1773"
"  File ""1773
, line  in "1784/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line ", line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in   File 349_call_impl, line  in "
_wrapped_call_impl""580/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py1773"_wrapped_call_impl" in 
1773_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.pyrun_once  File  in 
1784"  File 1784"__init__, line _wrapped_call_impl47  File "
"_wrapped_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line 
122
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
"_call_impl"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py_call_impl1784  File  in   File _capture_init/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py170""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in "spawn_main"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py, line ""  File 1773, line   File _call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py  File , line forward"1773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py, line " in 170"
"  File ""170
, line  in "1773/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_wrapped_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line ", line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in   File 47_wrapped_call_impl, line  in "
forward""269<string>170"forward" in 
170_wrapped_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py in " in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_capture_init  File  in 
1773"  File 1773"_create_eagle_worker, line forward361  File "
"forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py" in , line 
1
 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py
"_wrapped_call_impl"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py_wrapped_call_impl1773  File  in   File capture_one_batch_size/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1784""  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama_eagle3.py
, line "
 in "<module>"
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line ""  File 170, line   File _wrapped_call_impl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line _call_impl"469/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in 1784"
"""1784
, line  in "170/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.pyforward in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py
Extension modules:   File , line , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in   File 361forward, line  in "
_call_impl"numpy._core._multiarray_umath"1971784"_call_impl" in 
1784forward, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py,  in  in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pycapture_one_batch_size  File  in 
469"  File 469"numpy.linalg._umath_linalg_factory_call_impl500  File "
"_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line 

 in ", line ,   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py
"forward"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.pyforward469  File   File _capture_one_stream/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py1773pybase64._pybase64""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in ""
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py, , line ""  File 1784, line   File forward/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py  File , line _wrapped_call_impl"charset_normalizer.md120/usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py, line " in 1773"
"""1773
, line ,  in "1784/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py  File , line , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in   File 500requests.packages.charset_normalizer.mddecorate_context, line  in "
_wrapped_call_impl""1791773"_wrapped_call_impl" in , 
1773_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py in  in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py_capture_one_streamrequests.packages.chardet.md  File  in 
120"  File 120"create_draft_worker_wrapped_call_impl513  File "
"_wrapped_call_impl  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py" in , line , 

 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
"decorate_context"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.pydecorate_context120multidict._multidict  File   File capture/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py469""  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/nn/modules/module.py
, line "
 in , ""
" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py, line ""  File 1773, line   File decorate_contextyarl._quoting_c/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py  File , line forward"349/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py, line " in 469"
, """469
, line  in "1773/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py_wrapped_call_impl in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File propcache._helpers_c, line , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in   File 513run_once, line  in "
forward"", 514469"forward" in 
469_wrapped_call_impl, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pyaiohttp._http_writer in  in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.pycapture  File  in 
349"  File 349", init_model_workerforward229  File "
"forward  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py" in , line aiohttp._http_parser

 in ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py"
"run_once"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.pyrun_once349,   File   File capture/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py120", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/models/llama.py
, line "
 in aiohttp._websocket.mask"
"" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py47""  File 469, line   File run_once, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py, line decorate_context" in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py, line " in 120"
aiohttp._websocket.reader_c"""120
, line _capture_init"469/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.pyforward in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py  File , , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in , line   File 229
, line  in "
decorate_context""frozenlist._frozenlist315"decorate_context120" in   File 120forward, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in , , line 
 in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pycapture" in 
47"  File 47"__init__torch._C181  File "decorate_context
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pydecorate_context  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py" in , line 
,  in ", line 
  File "
"_capture_init"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py_capture_init47  File torch._C._dynamo.autograd_compiler__init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py349  File ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py
, line "
 in ", 
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py361""  File 120, line   File _capture_init/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pytorch._C._dynamo.eval_frame  File , line run_once/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line " in 349"
", "349
", line capture_one_batch_size"120/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pydecorate_context in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File , line torch._C._dynamo.guards/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in   File , line 181
, line  in "
run_once""2828, "run_once"349 in   File 349decorate_context, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in torch._C._dynamo.utils, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in __init__" in 
361"  File 361"run_scheduler_process, 35  File "run_once
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.pyrun_once  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py" in , line 
torch._C._fft in ", line 
  File "
"capture_one_batch_size"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.pycapture_one_batch_size361  File , __init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py47  File ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
, line "
 in "torch._C._linalg
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py500""  File 349, line   File capture_one_batch_size/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py,   File , line _capture_init/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py, line " in 47"
"torch._C._nested"47
", line _capture_one_stream"349/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.pyrun_once in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py  File , line , /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py in   File , line 35
, line  in "
_capture_init""108torch._C._nn"_capture_init"47 in   File 47run_once, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in , , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in __init__" in 
500"  File 500"runtorch._C._sparse261  File "_capture_init
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py_capture_init  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py" in , line 
,  in ", line 
  File "
"_capture_one_stream"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py_capture_one_stream500  File torch._C._specialinit_cuda_graphs/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py361  File ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py
, line "
 in "
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py513""  File 47, line ,   File _capture_one_stream/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py  File , line capture_one_batch_size/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line " in 361numpy.random._common"
""361
", line capture"47/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py_capture_init in , /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py in   File , line 261
, line  in "
capture_one_batch_sizenumpy.random.bit_generator""314"capture_one_batch_size"361 in   File 361_capture_init, line   File 
, , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in init_cuda_graphs" in 
513"  File numpy.random._bounded_integers513"_bootstrap148  File "capture_one_batch_size
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pycapture_one_batch_size  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py",  in , line 
 in ", line 
  File "
"capture"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.pynumpy.random._pcg64capture513  File __init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py500  File ", line   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
, line ", 
 in "
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py229""  File 361, line numpy.random._generator  File capture/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py  File , line _capture_one_stream/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py, line " in 500, "
""500
", line capture"361/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.pycapture_one_batch_size in numpy.random._mt19937/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py in   File , line 148
, line  in "
_capture_one_stream, ""135"_capture_one_stream"500 in   File 500capture_one_batch_size, line   File 
numpy.random._philox, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py in __init__" in 
229"  File , 229"_main580  File "_capture_one_stream
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py_capture_one_stream  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py"numpy.random._sfc64 in , line 
 in ", line 
  File "
"capture"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py, capture229  File __init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py513  File ", line 181 in __init__  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py
, line "numpy.random.mtrand
 in "
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
""  File 500, line   File , capture/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py  File , line capture/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py, line " in 513"acl
""513
", line ""500/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py_capture_one_stream in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py,  in   File , line 580/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py, line  in "
capture""122"torch_npu._Ccapture"513 in "513_capture_one_stream, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in __init__, , line  in 
181"  File 181"spawn_main269  File "capture
markupsafe._speedups35capture  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py" in , line 
 in ", line 
  File  in , 
"__init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py__init__181  File _create_eagle_worker/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py229  File "__init__yaml._yaml  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/cuda_graph_runner.py
, , line "
 in "
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
""  File psutil._psutil_linux513, line   File __init__<string>  File , line capture/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line ",  in 229"
""229
", line ""513/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.pyzmq.backend.cython._zmqcapture in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py in   File , line 269/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line  in "
, capture""1"capture"229 in "229capture, line   File cython.cimports.libc.math
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in , line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py in _create_eagle_worker, line  in 
35"  File , 35"<module>197  File "capture
261capture  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py"PIL._imaging in , line 
 in ", line 
  File  in 
"__init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py__init__35_factory, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py181  File "init_cuda_graphs  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py
, line "
 in 

Extension modules: sentencepiece._sentencepiece" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
""  File 229, line   File __init__  File numpy._core._multiarray_umath, , line __init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, line " in 181"
"regex._regex, 181
", line ""229/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.pycapture in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pynumpy.linalg._umath_linalg,  in   File , line 197/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line  in "
__init__"""npu_utils__init__"181 in ", 181capture, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line 
, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py in _factory, line pybase64._pybase64 in 
261"  File 261"179  File PIL._imagingft"__init__
148__init__,   File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py" in , line  in ", line 
,   File  in 
charset_normalizer.md"init_cuda_graphs"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.pyinit_cuda_graphs261create_draft_worker/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py35  File _cffi_backend"__init__  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_draft_extend_cuda_graph_runner.py, 
, line "
 in 
" in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, 
""requests.packages.charset_normalizer.md  File 181, line   File init_cuda_graphs  File , line __init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py"scipy._lib._ccallback_c  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py, line , " in 35"
"35
", line , ""181requests.packages.chardet.md/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py__init__ in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py in   File , line 179scipy.linalg._fblas/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line  in "
__init__"""__init__, "35 in , "35__init__, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line 
multidict._multidict/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py in create_draft_workerscipy.linalg._flapack, line  in 
148"  File 148"514  File , "__init__
, 580__init__  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py" in , line  in "yarl._quoting_c, line 
  File scipy.linalg.cython_lapack in 
"__init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py__init__148init_model_worker/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, 261  File ", __init__  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/eagle_draft_extend_npu_graph_runner.py
, line "
 in 
"propcache._helpers_c in "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyscipy.linalg._cythonized_array_utils
""  File 35, line   File __init__  File , line init_cuda_graphs, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py",   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line " in 261"
"261
aiohttp._http_writer", line scipy.linalg._solve_toeplitz""35/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py__init__ in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py in   File , , line 514, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line  in "
init_cuda_graphs"""init_cuda_graphs"aiohttp._http_parser261 in scipy.linalg._decomp_lu_cython"261__init__, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py,  in init_model_worker, , line  in 
580"  File 580"315  File "aiohttp._websocket.maskinit_cuda_graphs
scipy.linalg._matfuncs_sqrtm_triu269init_cuda_graphs  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py" in , line  in ", line , 
  File ,  in 
"__init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py__init__580__init__/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py148aiohttp._websocket.reader_c  File "scipy.linalg._matfuncs_expm_create_eagle_worker  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
, line "
 in 
" in , "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, 
""  File 261, line   File __init__  File , line __init__frozenlist._frozenlist/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py"scipy.linalg._linalg_pythran  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line " in 148"
"148
, ", line , ""261/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pyinit_cuda_graphs in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py in   File torch._C, line 315scipy.linalg.cython_blas/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line  in "
__init__"""__init__", 148 in , "148init_cuda_graphs, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.pytorch._C._dynamo.autograd_compiler in __init__scipy.linalg._decomp_update, line  in 
269"  File 269"2828  File ", __init__
, 197__init__  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py" in , line  in ", line torch._C._dynamo.eval_frame
  File scipy.sparse._sparsetools in 
"_create_eagle_worker"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py_create_eagle_worker269run_scheduler_process/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py580,   File ", _factory  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
, line "
 in 
" in torch._C._dynamo.guards"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_csparsetools
""  File 148, line   File _create_eagle_worker  File , line __init__, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py",   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py, line " in 580"
"580
torch._C._dynamo.utils", line scipy.sparse._csparsetools""148/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py__init__ in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in   File , , line 2828, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line  in "
__init__"""__init__"torch._C._fft580 in scipy.sparse.linalg._dsolve._superlu"580__init__, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py,  in run_scheduler_process, , line  in 
197"  File 197"108  File "torch._C._linalg__init__
scipy.sparse.linalg._eigen.arpack._arpack179__init__  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py" in , line  in ", line , 
  File ,  in 
"_factory"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py_factory197run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py269torch._C._nested  File "scipy.sparse.linalg._propack._spropackcreate_draft_worker  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py
, line "
 in 
" in , "/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, 
""  File 580, line   File _factory  File , line _create_eagle_workertorch._C._nn/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py"scipy.sparse.linalg._propack._dpropack  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line " in 269"
"269
, ", line , ""580/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py__init__ in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in   File torch._C._sparse, line 108scipy.sparse.linalg._propack._cpropack/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line  in "
_create_eagle_worker"""_create_eagle_worker", 269 in , "269__init__, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pytorch._C._special in runscipy.sparse.linalg._propack._zpropack, line  in 
179"  File 179"314  File "_create_eagle_worker
, 514_create_eagle_worker  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py" in , line  in , ", line 
  File scipy.sparse.csgraph._tools in 
"create_draft_worker"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pycreate_draft_worker179_bootstrapnumpy.random._common/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py197  File ", init_model_worker  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
, line "
 in 
, " in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyscipy.sparse.csgraph._shortest_path
""  File 269, line   File create_draft_worker  File numpy.random.bit_generator, line _factory/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py",   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line " in 197"
", 197
", line scipy.sparse.csgraph._traversal""269/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_create_eagle_worker in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pynumpy.random._bounded_integers in   File , line 314, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line  in "
_factory""", _factory"197 in scipy.sparse.csgraph._min_spanning_tree"197_create_eagle_worker, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line numpy.random._pcg64
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py in _bootstrap, , line  in 
514"  File 514"135,   File "
_factoryscipy.sparse.csgraph._flow315_factory  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py" in , line  in numpy.random._generator", line   File 
,  in 
"init_model_worker"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pyinit_model_worker514_main, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py179"  File scipy.sparse.csgraph._matching__init__  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
, line "
 in 
numpy.random._mt19937" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", 
""  File 197, line   File init_model_worker  File , , line create_draft_worker"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.pyscipy.sparse.csgraph._reordering  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py, line " in 179"
"numpy.random._philox179
, line ", ""197/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_factory in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py,  in   File 135, line scipy.optimize._group_columns/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line  in "
create_draft_worker"""numpy.random._sfc64create_draft_worker" in 179, "179_factory, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line , 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_main in scipy._lib.messagestream, line  in 
315"  File 315"122numpy.random.mtrand  File "
create_draft_worker, 2828create_draft_worker  File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py" in , line  in , ", line   File 
scipy.optimize._trlib._trlib in 
  File ""__init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py__init__315spawn_mainacl/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py514"  File , run_scheduler_process/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/spec_info.py
, line "
 in 
" in , /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py"scipy.optimize._lbfgsb
""  File 179, line   File __init__  File , line init_model_workertorch_npu._C"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py,   File , line , line " in 514"
"514
, line "_moduleTNC, "514179/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pycreate_draft_worker in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py  File <string> in   File 122, line , markupsafe._speedups/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in  in "
init_model_worker"""init_model_worker" in 514scipy.optimize._moduleTNC", init_model_workercreate_draft_worker, line   File 
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, line 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyspawn_main in , , line yaml._yaml

2828"  File 2828"1  File "
init_model_workerscipy.optimize._cobyla108  File   File  in , /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py" in , line  in ", line   File 
,  in ""run_scheduler_processpsutil._psutil_linux"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyrun_scheduler_process2828<module>/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py315"  File scipy.optimize._slsqprun/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py
, , line "
 in 
" in <string>", 
""  File zmq.backend.cython._zmq514, line   File run_scheduler_process, line __init__"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyscipy.optimize._minpack  File , line , line " in , 315"
315
Extension modules: 
, line ", "315514/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyinit_model_workercython.cimports.libc.math in /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py  File  in numpy._core._multiarray_umath  File 1, line scipy.optimize._lsq.givens_elimination/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in  in "
__init__, ""__init__",  in 315, "__init__init_model_worker, line   File 
PIL._imaging, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pynumpy.linalg._umath_linalg<module> in scipy.optimize._zeros, line 

108"  File 108"  File ", 
__init__, 314  File ,   File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py" in , line ", line sentencepiece._sentencepiece
scipy.optimize._cython_nnls in "pybase64._pybase64"run"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pyrun108/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py2828  File , 
Extension modules: , _bootstrap/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, 
, line "
 in " in "regex._regexnumpy._core._multiarray_umathscipy._lib._uarray._uarray
""charset_normalizer.md  File 315, line   File run, line run_scheduler_process/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, , ,   File , line , line , " in 2828"
2828
"npu_utilsscipy.special._ufuncs_cxxnumpy.linalg._umath_linalg"2828315requests.packages.charset_normalizer.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py__init__ in /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py  File  in   File , line , , /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py in  in , "
, run_scheduler_process""run_scheduler_process"2828PIL._imagingftscipy.special._ufuncs"run_scheduler_process__init__requests.packages.chardet.md, line   File pybase64._pybase64
, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in , , , line 

314"  File , 314"  File ", run_scheduler_processscipy.special._specfun_cffi_backend135  File   File  in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py"charset_normalizer.md in , line ", line multidict._multidict
, ,  in ""_bootstrap"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py_bootstrap, 314/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py108,   File scipy.special._combscipy._lib._ccallback_c_main/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py
, line "
requests.packages.charset_normalizer.md in " in yarl._quoting_c", , 
""  File 2828, line   File , _bootstrap, line run, /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyscipy.special._ellip_harm_2scipy.linalg._fblas  File , line , line " in 108"requests.packages.chardet.md
108
propcache._helpers_c", , "1082828/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pyrun_scheduler_process in /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py  File  in   File , , line scipy.linalg._decomp_interpolativescipy.linalg._flapack, /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py in  in "
run""run"aiohttp._http_writer108, , multidict._multidict"runrun_scheduler_process, line   File 
, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py
/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py,  in scipy.optimize._bglu_densescipy.linalg.cython_lapack, , line 

135"  File 135"  File "aiohttp._http_parserrun, yarl._quoting_c, 122  File   File  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py" in , line ", line , 
scipy.optimize._lsapscipy.linalg._cythonized_array_utils,  in ""_main"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py_main135/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py314aiohttp._websocket.mask  File , propcache._helpers_c, spawn_main/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
, line "
 in " in , "scipy.spatial._ckdtreescipy.linalg._solve_toeplitz, , 
""  File 108, line   File _main, line _bootstrapaiohttp._websocket.reader_c/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, aiohttp._http_writerscipy.linalg._decomp_lu_cython  File , line , line " in 314"
314
, "scipy.spatial._qhull, , "314108/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pyrun in /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py  File  in   File frozenlist._frozenlist, line , aiohttp._http_parserscipy.linalg._matfuncs_sqrtm_triu<string> in  in "
_bootstrap""_bootstrap"314, scipy.spatial._voronoi, , "_bootstraprun, line   File 
, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py in torch._C, aiohttp._websocket.maskscipy.linalg._matfuncs_expm, line 

122"  File 122"  File "_bootstrap, scipy.spatial._distance_wrap, , 1  File   File  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py" in , line ", line 
torch._C._dynamo.autograd_compiler, aiohttp._websocket.reader_cscipy.linalg._linalg_pythran in ""spawn_main"/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pyspawn_main122/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py135  File , scipy.spatial._hausdorff, , <module>/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
, line "
 in " in "torch._C._dynamo.eval_frame, frozenlist._frozenlistscipy.linalg.cython_blas
""  File 314, line   File spawn_main, line _main/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, scipy.spatial.transform._rotation, , , line , line " in 135"
135
"torch._C._dynamo.guards, torch._Cscipy.linalg._decomp_update135
Extension modules: 314<string>_bootstrap in <string>  File  in   File , line , scipy.optimize._direct, ,  in numpy._core._multiarray_umath in "
_main""_main"135torch._C._dynamo.utilstorch._C._dynamo.autograd_compilerscipy.sparse._sparsetools, _main_bootstrap, , line   File 
, line <string>
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py in , , , setproctitle._setproctitle

numpy.linalg._umath_linalg1"  File 1"  File "_maintorch._C._ffttorch._C._dynamo.eval_frame_csparsetools  File ,   File  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", line 122 in , line ", , line 
, , , "Cython.Utils"<module>" in <module>1/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pypybase64._pybase64122  File torch._C._linalgtorch._C._dynamo.guardsscipy.sparse._csparsetools/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py
, line spawn_main
 in " in , ", , , "Cython.Plex.Actions"135
<module>, line spawn_maincharset_normalizer.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pytorch._C._nestedtorch._C._dynamo.utilsscipy.sparse.linalg._dsolve._superlu, line , , line  in 
Extension modules:   File 
122
Extension modules: 
, ", , , 122Cython.Plex.Transitions135_mainnumpy._core._multiarray_umath" in numpy._core._multiarray_umath  File requests.packages.charset_normalizer.md, line torch._C._nntorch._C._fftscipy.sparse.linalg._eigen.arpack._arpack in ,  in 
<string>, spawn_main
Extension modules: ", , 122, , , spawn_mainCython.Plex.Machines_main  File "numpy.linalg._umath_linalg
numpy._core._multiarray_umath<string>numpy.linalg._umath_linalgrequests.packages.chardet.md in torch._C._sparsetorch._C._linalgscipy.sparse.linalg._propack._spropack, 
, 
", line   File ", spawn_main, , torch._C._nested, ,   File Cython.Plex.DFA  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py1, ", line numpy.linalg._umath_linalg
pybase64._pybase64torch._C._special, scipy.sparse.linalg._propack._dpropackpybase64._pybase64", "" in multidict._multidict<string>1  File , torch._C._nn, , <string>, Cython.Plex.Scanners/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, line <module>, " in "charset_normalizer.mdscipy.sparse.linalg._propack._cpropack, , pybase64._pybase64"charset_normalizer.md, "122
yarl._quoting_c, line <module><string>, torch._C._sparse, numpy.random._common, line , Cython.Compiler.Scanning, , line  in , 1
"requests.packages.charset_normalizer.mdscipy.sparse.linalg._propack._zpropack, , 1charset_normalizer.md, requests.packages.charset_normalizer.md122spawn_mainpropcache._helpers_c in 
Extension modules: , line , torch._C._special, numpy.random.bit_generator in Cython.StringIOTree, ,  in 
, <module>numpy._core._multiarray_umath1
Extension modules: requests.packages.chardet.mdscipy.sparse.csgraph._tools, <module>, requests.packages.charset_normalizer.mdrequests.packages.chardet.mdspawn_main  File aiohttp._http_writer
 in , , numpy._core._multiarray_umath, numpy.random._bounded_integers
Cython.Compiler.Code, 
", , <module>numpy.linalg._umath_linalgnumpy.random._common, scipy.sparse.csgraph._shortest_path, , requests.packages.chardet.md,   File <string>multidict._multidictaiohttp._http_parser

Extension modules: , multidict._multidict, numpy.linalg._umath_linalgnumpy.random._pcg64, google._upb._message""
Extension modules: , , numpy._core._multiarray_umathnumpy.random.bit_generator, , scipy.sparse.csgraph._traversal, pybase64._pybase64<string>, line , numpy._core._multiarray_umathyarl._quoting_caiohttp._websocket.mask, , , multidict._multidictyarl._quoting_c, numpy.random._generator
Extension modules: "1, pybase64._pybase64, , , msgspec._corenumpy.linalg._umath_linalgnumpy.random._bounded_integers, , scipy.sparse.csgraph._min_spanning_tree, numpy._core._multiarray_umath, line  in charset_normalizer.mdnumpy.linalg._umath_linalg, propcache._helpers_caiohttp._websocket.reader_c, , yarl._quoting_cpropcache._helpers_c, numpy.random._mt199371, <module>, charset_normalizer.md, pyarrow.lib, numpy.random._pcg64, , scipy.sparse.csgraph._flow, ,  in pybase64._pybase64
requests.packages.charset_normalizer.md, aiohttp._http_writer, frozenlist._frozenlist, pybase64._pybase64, propcache._helpers_c, aiohttp._http_writernumpy.random._philox<module>, , requests.packages.charset_normalizer.md, pandas._libs.tslibs.ccalendarnumpy.random._generator, numpy.linalg._umath_linalg, , scipy.sparse.csgraph._matching, , 
charset_normalizer.mdrequests.packages.chardet.md
Extension modules: , aiohttp._http_parser, , torch._Ccharset_normalizer.mdaiohttp._http_writer, aiohttp._http_parsernumpy.random._sfc64, numpy._core._multiarray_umathrequests.packages.chardet.md, pandas._libs.tslibs.np_datetimenumpy.random._mt19937, , , , scipy.sparse.csgraph._reordering, , requests.packages.charset_normalizer.md
Extension modules: , aiohttp._websocket.mask, , torch._C._dynamo.autograd_compilermultidict._multidictrequests.packages.charset_normalizer.mdaiohttp._http_parser, , aiohttp._websocket.masknumpy.random.mtrand, numpy._core._multiarray_umathnumpy.linalg._umath_linalg, pandas._libs.tslibs.dtypesnumpy.random._philox, , , , multidict._multidictscipy.optimize._group_columns, requests.packages.chardet.md, acl, aiohttp._websocket.reader_c, , , torch._C._dynamo.eval_frameyarl._quoting_crequests.packages.chardet.md, aiohttp._websocket.mask, , aiohttp._websocket.reader_cnumpy.linalg._umath_linalgpandas._libs.tslibs.base, numpy.random._sfc64torch_npu._C, , pybase64._pybase64, , yarl._quoting_cscipy._lib.messagestream, , frozenlist._frozenlist, , torch._C._dynamo.guards, propcache._helpers_cmultidict._multidict, aiohttp._websocket.reader_c, , , frozenlist._frozenlistpandas._libs.tslibs.nattypemultidict._multidict, numpy.random.mtrand, pybase64._pybase64, , charset_normalizer.md, , markupsafe._speedupspropcache._helpers_cscipy.optimize._trlib._trlib, , , torch._C, torch._C._dynamo.utilspybase64._pybase64, aiohttp._http_writer, yarl._quoting_cfrozenlist._frozenlist, , , torch._Cpandas._libs.tslibs.timezonesyarl._quoting_c, acl, charset_normalizer.md, requests.packages.charset_normalizer.md, , yaml._yamlaiohttp._http_writerscipy.optimize._lbfgsb, , , torch._C._dynamo.autograd_compilertorch._C._fft, , aiohttp._http_parser, propcache._helpers_ctorch._C, , torch._C._dynamo.autograd_compiler, pandas._libs.tslibs.fieldspropcache._helpers_c, , , torch_npu._Crequests.packages.charset_normalizer.md, requests.packages.chardet.md, , aiohttp._http_parser_moduleTNC, psutil._psutil_linux, , torch._C._dynamo.eval_framecharset_normalizer.mdtorch._C._linalg, aiohttp._websocket.maskaiohttp._http_writertorch._C._dynamo.autograd_compiler, , , torch._C._dynamo.eval_frame, pandas._libs.tslibs.timedeltas, aiohttp._http_writer, , requests.packages.chardet.md, , , markupsafe._speedupsaiohttp._websocket.maskscipy.optimize._moduleTNC, zmq.backend.cython._zmq, , multidict._multidict, torch._C._dynamo.guardstorch._C._nestedaiohttp._websocket.reader_caiohttp._http_parsertorch._C._dynamo.eval_frame, , , , torch._C._dynamo.guardsrequests.packages.charset_normalizer.md, pandas._libs.tslibs.tzconversion, aiohttp._http_parser, , , , , aiohttp._websocket.reader_cyaml._yamlmultidict._multidictscipy.optimize._cobyla, , cython.cimports.libc.math, yarl._quoting_c, torch._C._dynamo.utilstorch._C._nnfrozenlist._frozenlistaiohttp._websocket.masktorch._C._dynamo.guards, , , torch._C._dynamo.utils, requests.packages.chardet.mdpandas._libs.tslibs.timestamps, , aiohttp._websocket.mask, , , , , frozenlist._frozenlistyarl._quoting_cscipy.optimize._slsqp, psutil._psutil_linux, PIL._imagingpropcache._helpers_c, torch._C._ffttorch._C._sparsetorch._Caiohttp._websocket.reader_ctorch._C._dynamo.utils, , , torch._C._fft, pandas._libs.properties, aiohttp._websocket.reader_c, , , , , , torch._Cpropcache._helpers_cscipy.optimize._minpack, zmq.backend.cython._zmq, aiohttp._http_writer, torch._C._linalgtorch._C._specialsentencepiece._sentencepiecetorch._C._dynamo.autograd_compilerfrozenlist._frozenlisttorch._C._fft, , , torch._C._linalgpandas._libs.tslibs.offsets, , frozenlist._frozenlist, , , , , torch._C._dynamo.autograd_compileraiohttp._http_writerscipy.optimize._lsq.givens_elimination, , cython.cimports.libc.mathaiohttp._http_parsertorch._C._nested, regex._regextorch._C._dynamo.eval_frametorch._C, torch._C._linalg, , , torch._C._nestedpandas._libs.tslibs.strptime, , , torch._C, , , numpy.random._common, torch._C._dynamo.eval_frameaiohttp._http_parserscipy.optimize._zeros, , PIL._imagingaiohttp._websocket.masktorch._C._nn, torch._C._dynamo.guardsnpu_utilstorch._C._dynamo.autograd_compiler, torch._C._nested, , , torch._C._nnpandas._libs.tslibs.parsing, , torch._C._dynamo.autograd_compiler, , , , , numpy.random.bit_generator, torch._C._dynamo.guardsaiohttp._websocket.maskscipy.optimize._cython_nnls, , aiohttp._websocket.reader_ctorch._C._sparsetorch._C._dynamo.utilstorch._C._dynamo.eval_frame, sentencepiece._sentencepiecePIL._imagingfttorch._C._dynamo.eval_frame, torch._C._nn, , torch._C._sparse, pandas._libs.tslibs.conversion, , torch._C._fft, , , , , numpy.random._bounded_integers, torch._C._dynamo.utilsaiohttp._websocket.reader_c, scipy._lib._uarray._uarray, frozenlist._frozenlisttorch._C._specialtorch._C._dynamo.guardstorch._C._linalg, regex._regextorch._C._dynamo.guards_cffi_backend, torch._C._sparse, , torch._C._special, pandas._libs.tslibs.period, torch._C._dynamo.utils, , , numpy.random._pcg64, , torch._C._fftfrozenlist._frozenlistscipy.special._ufuncs_cxx, , torch._C, torch._C._nestednpu_utilstorch._C._dynamo.utils, scipy._lib._ccallback_ctorch._C._special, , , , numpy.random._commonpandas._libs.tslibs.vectorized, torch._C._fft, , , numpy.random._generator, torch._C._linalgnumpy.random._commontorch._Cscipy.special._ufuncs, , torch._C._dynamo.autograd_compiler, torch._C._nnPIL._imagingfttorch._C._fft, , scipy.linalg._fblas, , , , numpy.random.bit_generatorpandas._libs.ops_dispatch, torch._C._linalg, , numpy.random._common, numpy.random._mt19937, torch._C._nestednumpy.random.bit_generatortorch._C._dynamo.autograd_compilerscipy.special._specfun, , torch._C._dynamo.eval_frame, torch._C._sparsetorch._C._linalg, _cffi_backendscipy.linalg._flapack, , , , , numpy.random._bounded_integerspandas._libs.missing, torch._C._nested, , numpy.random.bit_generator, , numpy.random._philoxtorch._C._nnnumpy.random._bounded_integerstorch._C._dynamo.eval_framescipy.special._comb, , torch._C._dynamo.guardstorch._C._special, torch._C._nested, scipy._lib._ccallback_cscipy.linalg.cython_lapack, , , , , numpy.random._pcg64pandas._libs.hashtable, torch._C._nn, numpy.random._bounded_integers, , numpy.random._sfc64torch._C._sparsenumpy.random._pcg64torch._C._dynamo.guardsscipy.special._ellip_harm_2, , torch._C._dynamo.utils, torch._C._nn, , scipy.linalg._fblasscipy.linalg._cythonized_array_utils, , , , , numpy.random._generatorpandas._libs.algos, torch._C._sparse, numpy.random._commonnumpy.random._pcg64, , numpy.random.mtrand, torch._C._specialnumpy.random._generatortorch._C._dynamo.utilsscipy.linalg._decomp_interpolative, , torch._C._fft, , torch._C._sparse, numpy.random.bit_generatorscipy.linalg._flapackscipy.linalg._solve_toeplitz, , , , , numpy.random._mt19937pandas._libs.interval, torch._C._specialmultidict._multidict, numpy.random._generator, , , aclscipy.linalg._decomp_lu_cythonnumpy.random._mt19937torch._C._fftscipy.optimize._bglu_dense, , torch._C._linalgtorch._C._special, numpy.random._bounded_integersnumpy.random._commonscipy.linalg.cython_lapack, , , , , numpy.random._philoxpandas._libs.lib, , numpy.random._mt19937, , , , scipy.linalg._matfuncs_sqrtm_triunumpy.random._philoxtorch._C._linalgtorch_npu._Cscipy.optimize._lsap, , torch._C._nestednumpy.random._common, , yarl._quoting_cnumpy.random._pcg64numpy.random.bit_generatorscipy.linalg._cythonized_array_utils, , , , numpy.random._sfc64pyarrow._compute, , , numpy.random._commonnumpy.random._philox, , , scipy.linalg._matfuncs_expm, numpy.random._sfc64torch._C._nestedscipy.spatial._ckdtree, , torch._C._nnmarkupsafe._speedupsnumpy.random.bit_generator, , numpy.random._generatornumpy.random._bounded_integersscipy.linalg._solve_toeplitz, propcache._helpers_c, , , numpy.random.mtrandpandas._libs.ops, , , , numpy.random.bit_generatornumpy.random._sfc64, , , scipy.linalg._linalg_pythrannumpy.random.mtrandtorch._C._nnscipy.spatial._qhull, torch._C._sparsepandas._libs.hashingyaml._yamlnumpy.random._bounded_integers, , numpy.random._mt19937numpy.random._pcg64, scipy.linalg._decomp_lu_cython, , , , acl, , , numpy.random._bounded_integersnumpy.random.mtrand, , , aiohttp._http_writer, scipy.linalg.cython_blasacltorch._C._sparsescipy.spatial._voronoitorch._C._specialpandas._libs.arraysnumpy.random._pcg64, , , psutil._psutil_linuxnumpy.random._philoxnumpy.random._generatorscipy.linalg._matfuncs_sqrtm_triu, , , , , , , torch_npu._Cnumpy.random._pcg64acl, , , , scipy.linalg._decomp_updateaiohttp._http_parsertorch._C._specialtorch_npu._C, scipy.spatial._distance_wrappandas._libs.tslibnumpy.random._generator, zmq.backend.cython._zmq, numpy.random._sfc64numpy.random._mt19937scipy.linalg._matfuncs_expm, , numpy.random._common, , , , , numpy.random._generatortorch_npu._C, , , , markupsafe._speedupsscipy.sparse._sparsetools, , aiohttp._websocket.maskscipy.spatial._hausdorffpandas._libs.sparsenumpy.random._mt19937markupsafe._speedups, cython.cimports.libc.mathnumpy.random.mtrandnumpy.random._philox, scipy.linalg._linalg_pythran, , numpy.random._commonnumpy.random.bit_generator, , , , numpy.random._mt19937, , , , markupsafe._speedups, yaml._yaml_csparsetools, , scipy.spatial.transform._rotationaiohttp._websocket.reader_cpandas._libs.internalsnumpy.random._philox, yaml._yamlPIL._imagingaclnumpy.random._sfc64scipy.linalg.cython_blas, , numpy.random.bit_generatornumpy.random._bounded_integers, , , , numpy.random._philox, , , , yaml._yaml, scipy.sparse._csparsetools, , , scipy.optimize._directpsutil._psutil_linuxpandas._libs.indexingnumpy.random._sfc64, psutil._psutil_linuxnumpy.random.mtrandscipy.linalg._decomp_updatetorch_npu._Csentencepiece._sentencepiece, , numpy.random._bounded_integersfrozenlist._frozenlistnumpy.random._pcg64, , , , numpy.random._sfc64, , , scipy.sparse.linalg._dsolve._superlu, psutil._psutil_linux, , , zmq.backend.cython._zmqpandas._libs.indexsetproctitle._setproctitlenumpy.random.mtrand, zmq.backend.cython._zmqaclscipy.sparse._sparsetools, regex._regex, numpy.random._pcg64markupsafe._speedupsnumpy.random._generator, , , , numpy.random.mtrand, , , scipy.sparse.linalg._eigen.arpack._arpack, zmq.backend.cython._zmq, , , , pandas._libs.writerscython.cimports.libc.mathCython.Utilsacltorch._C, cython.cimports.libc.math_csparsetools, torch_npu._C, npu_utilsnumpy.random._generatoryaml._yamlnumpy.random._mt19937, , , acl, , , scipy.sparse.linalg._propack._spropack, cython.cimports.libc.math, , , , pandas._libs.joinCython.Plex.Actions, PIL._imagingscipy.sparse._csparsetoolstorch_npu._C, PIL._imaging, torch._C._dynamo.autograd_compiler, PIL._imagingftnumpy.random._mt19937markupsafe._speedupsnumpy.random._philox, , psutil._psutil_linux, torch_npu._Cscipy.sparse.linalg._propack._dpropack, , PIL._imaging, , , , , , pandas._libs.window.aggregationsCython.Plex.Transitions, scipy.sparse.linalg._dsolve._superlu, sentencepiece._sentencepiecetorch._C._dynamo.eval_framesentencepiece._sentencepiece, markupsafe._speedups, _cffi_backendnumpy.random._philoxnumpy.random._sfc64yaml._yaml, , zmq.backend.cython._zmq, scipy.sparse.linalg._propack._cpropack, , markupsafe._speedups, sentencepiece._sentencepiece, , , , pandas._libs.window.indexersCython.Plex.Machines, scipy.sparse.linalg._eigen.arpack._arpack, , regex._regextorch._C._dynamo.guardsregex._regex, , yaml._yamlscipy._lib._ccallback_cnumpy.random._sfc64numpy.random.mtrand, , psutil._psutil_linux, cython.cimports.libc.mathscipy.sparse.linalg._propack._zpropack, , yaml._yaml, regex._regex, , pandas._libs.reshape, , Cython.Plex.DFA, scipy.sparse.linalg._propack._spropack, , torch._C._dynamo.utilsnpu_utilsnpu_utilsscipy.linalg._fblas, , numpy.random.mtrand, aclpsutil._psutil_linux, zmq.backend.cython._zmq, PIL._imagingscipy.sparse.csgraph._tools, , , , npu_utilspsutil._psutil_linuxpandas._libs.groupby, , Cython.Plex.Scanners, scipy.sparse.linalg._propack._dpropack, , PIL._imagingfttorch._C._fftPIL._imagingft, scipy.linalg._flapack, , , aclzmq.backend.cython._zmq, torch_npu._C, cython.cimports.libc.mathscipy.sparse.csgraph._shortest_path, , sentencepiece._sentencepiece, , PIL._imagingftzmq.backend.cython._zmqpandas._libs.json, Cython.Compiler.Scanning, scipy.sparse.linalg._propack._cpropack, , _cffi_backend, torch._C._linalg_cffi_backend, scipy.linalg.cython_lapack, , , torch_npu._C, cython.cimports.libc.math, PIL._imagingscipy.sparse.csgraph._traversalmarkupsafe._speedups, , , regex._regex, _cffi_backendcython.cimports.libc.mathpandas._libs.parsersCython.StringIOTreescipy.sparse.linalg._propack._zpropack, , , scipy._lib._ccallback_c, torch._C._nested, scipy._lib._ccallback_cscipy.linalg._cythonized_array_utils, , , , , , PIL._imagingscipy.sparse.csgraph._min_spanning_treemarkupsafe._speedups, yaml._yamlsentencepiece._sentencepiece, , , npu_utilsscipy._lib._ccallback_cPIL._imagingpandas._libs.testingCython.Compiler.Codescipy.sparse.csgraph._tools, scipy.linalg._fblas, scipy.linalg._fblas, torch._C._nn, , scipy.linalg._solve_toeplitz, , , , , scipy.sparse.csgraph._flow, , yaml._yaml, regex._regexsentencepiece._sentencepiece, psutil._psutil_linux, PIL._imagingftscipy.linalg._fblaspyarrow._parquetscipy.sparse.csgraph._shortest_pathgoogle._upb._message, sentencepiece._sentencepiecescipy.linalg._flapackscipy.linalg._flapack, , torch._C._sparse, , scipy.linalg._decomp_lu_cython, , , , scipy.sparse.csgraph._matching, , , npu_utilspsutil._psutil_linux, regex._regex, zmq.backend.cython._zmq, scipy.linalg._flapack_cffi_backendpyarrow._fsscipy.sparse.csgraph._traversal, regex._regexscipy.linalg.cython_lapackscipy.linalg.cython_lapack, , msgspec._coretorch._C._special, scipy.linalg._matfuncs_sqrtm_triu, , , , , scipy.sparse.csgraph._reordering, , , PIL._imagingftzmq.backend.cython._zmqnpu_utils, , cython.cimports.libc.mathscipy.linalg.cython_lapackscipy._lib._ccallback_cpyarrow._azurefsscipy.sparse.csgraph._min_spanning_tree, scipy.linalg._cythonized_array_utilsnpu_utilsscipy.linalg._cythonized_array_utils, , , pyarrow.libscipy.linalg._matfuncs_expm, , , , , scipy.optimize._group_columns, , , _cffi_backendcython.cimports.libc.mathPIL._imagingft, scipy.linalg._cythonized_array_utils, PIL._imagingscipy.linalg._fblaspyarrow._hdfsscipy.sparse.csgraph._flow, scipy.linalg._solve_toeplitzPIL._imagingftscipy.linalg._solve_toeplitz, , pandas._libs.tslibs.ccalendar, , scipy.linalg._linalg_pythran, , , scipy._lib.messagestream, , , scipy._lib._ccallback_c, PIL._imaging, _cffi_backendscipy.linalg._solve_toeplitz, scipy.linalg._flapackpyarrow._gcsfsscipy.sparse.csgraph._matching, sentencepiece._sentencepiecescipy.linalg._decomp_lu_cythonscipy.linalg._decomp_lu_cython, _cffi_backendpandas._libs.tslibs.np_datetime, , scipy.linalg.cython_blas, , , , scipy.optimize._trlib._trlib, , , scipy.linalg._fblas, , scipy._lib._ccallback_cscipy.linalg._decomp_lu_cython, scipy.linalg.cython_lapacksentencepiece._sentencepiecepyarrow._s3fsscipy.sparse.csgraph._reordering, regex._regexscipy.linalg._matfuncs_sqrtm_triuscipy.linalg._matfuncs_sqrtm_triu, scipy._lib._ccallback_cpandas._libs.tslibs.dtypes, , scipy.linalg._decomp_update, , , , scipy.optimize._lbfgsb, , , scipy.linalg._flapack, , scipy.linalg._fblasscipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._cythonized_array_utilsregex._regexxxhash._xxhashscipy.optimize._group_columns, scipy.linalg._matfuncs_expmnpu_utilsscipy.linalg._matfuncs_expm, scipy.linalg._fblaspandas._libs.tslibs.base, , scipy.sparse._sparsetools, , , , _moduleTNC, , , scipy.linalg.cython_lapack, , scipy.linalg._flapackscipy.linalg._matfuncs_expm, scipy.linalg._solve_toeplitzpyarrow._aceronpu_utilsscipy._lib.messagestream, scipy.linalg._linalg_pythranPIL._imagingftscipy.linalg._linalg_pythran, scipy.linalg._flapackpandas._libs.tslibs.nattype, , _csparsetools, , , , scipy.optimize._moduleTNC, , scipy.linalg._cythonized_array_utils, , , scipy.linalg.cython_lapackscipy.linalg._linalg_pythran, scipy.linalg._decomp_lu_cythonpyarrow._csvPIL._imagingftscipy.optimize._trlib._trlib, scipy.linalg.cython_blasscipy.linalg.cython_blas, _cffi_backendscipy.linalg.cython_lapackpandas._libs.tslibs.timezones, , scipy.sparse._csparsetools, , , scipy.optimize._cobyla, , , scipy.linalg._solve_toeplitz, , , scipy.linalg._cythonized_array_utilsscipy.linalg.cython_blas, scipy.linalg._matfuncs_sqrtm_triupyarrow._jsonscipy.optimize._lbfgsb, _cffi_backendscipy.linalg._decomp_updatescipy.linalg._decomp_update, scipy._lib._ccallback_cscipy.linalg._cythonized_array_utilspandas._libs.tslibs.fields, , scipy.sparse.linalg._dsolve._superlu, , , scipy.optimize._slsqp, , , scipy.linalg._decomp_lu_cython, , , scipy.linalg._solve_toeplitzscipy.linalg._decomp_update, scipy.linalg._matfuncs_expmpyarrow._substrait_moduleTNC, scipy._lib._ccallback_cscipy.sparse._sparsetoolsscipy.sparse._sparsetools, scipy.linalg._fblasscipy.linalg._solve_toeplitzpandas._libs.tslibs.timedeltas, , scipy.sparse.linalg._eigen.arpack._arpack, , , scipy.optimize._minpack, , , scipy.linalg._matfuncs_sqrtm_triu, , , scipy.linalg._decomp_lu_cythonscipy.sparse._sparsetools, scipy.linalg._linalg_pythranpyarrow._datasetscipy.optimize._moduleTNC, scipy.linalg._fblas_csparsetools_csparsetools, scipy.linalg._flapackscipy.linalg._decomp_lu_cythonpandas._libs.tslibs.tzconversion, , scipy.sparse.linalg._propack._spropack, , , scipy.optimize._lsq.givens_elimination, , , scipy.linalg._matfuncs_expm, , , scipy.linalg._matfuncs_sqrtm_triu_csparsetools, scipy.linalg.cython_blaspyarrow._dataset_orcscipy.optimize._cobyla, scipy.linalg._flapackscipy.sparse._csparsetoolsscipy.sparse._csparsetools, scipy.linalg.cython_lapackscipy.linalg._matfuncs_sqrtm_triupandas._libs.tslibs.timestamps, , scipy.sparse.linalg._propack._dpropack, , , scipy.optimize._zeros, , , scipy.linalg._linalg_pythran, , , scipy.linalg._matfuncs_expmscipy.sparse._csparsetools, scipy.linalg._decomp_updatepyarrow._parquet_encryptionscipy.optimize._slsqp, scipy.linalg.cython_lapackscipy.sparse.linalg._dsolve._superluscipy.sparse.linalg._dsolve._superlu, scipy.linalg._cythonized_array_utilsscipy.linalg._matfuncs_expm, pandas._libs.properties, , scipy.sparse.linalg._propack._cpropack, , , scipy.optimize._cython_nnls, , , scipy.linalg.cython_blas, , numpy.random._common, scipy.linalg._linalg_pythranscipy.sparse.linalg._dsolve._superlu, scipy.sparse._sparsetoolspyarrow._dataset_parquet_encryptionscipy.optimize._minpack, scipy.linalg._cythonized_array_utilsscipy.sparse.linalg._eigen.arpack._arpackscipy.sparse.linalg._eigen.arpack._arpack, scipy.linalg._solve_toeplitzscipy.linalg._linalg_pythranpandas._libs.tslibs.offsets, , , scipy.sparse.linalg._propack._zpropack, , , scipy._lib._uarray._uarray, , , scipy.linalg._decomp_update, , , numpy.random.bit_generatorscipy.linalg.cython_blasscipy.sparse.linalg._eigen.arpack._arpack, _csparsetoolspyarrow._dataset_parquetscipy.optimize._lsq.givens_elimination, scipy.linalg._solve_toeplitzscipy.sparse.linalg._propack._spropackscipy.sparse.linalg._propack._spropack, scipy.linalg._decomp_lu_cythonscipy.linalg.cython_blaspandas._libs.tslibs.strptime, , , scipy.sparse.csgraph._tools, , scipy.special._ufuncs_cxx, , , scipy.sparse._sparsetools, , , numpy.random._bounded_integersscipy.linalg._decomp_updatescipy.sparse.linalg._propack._spropack, scipy.sparse._csparsetoolsscipy.optimize._zeros, scipy.linalg._decomp_lu_cythonscipy.sparse.linalg._propack._dpropackscipy.sparse.linalg._propack._dpropack, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg._decomp_updatepandas._libs.tslibs.parsing, , , scipy.sparse.csgraph._shortest_path, , scipy.special._ufuncs, , , _csparsetools, __triton_launcher, , scipy.sparse._sparsetoolsscipy.sparse.linalg._propack._dpropacknumpy.random._pcg64, scipy.sparse.linalg._dsolve._superluscipy.optimize._cython_nnls, scipy.linalg._matfuncs_sqrtm_triuscipy.sparse.linalg._propack._cpropackscipy.sparse.linalg._propack._cpropack, scipy.linalg._matfuncs_expm (total: scipy.sparse._sparsetoolspandas._libs.tslibs.conversion, , , scipy.sparse.csgraph._traversal, , scipy.special._specfun, , , scipy.sparse._csparsetools, 174, , _csparsetoolsscipy.sparse.linalg._propack._cpropacknumpy.random._generator, scipy.sparse.linalg._eigen.arpack._arpackscipy._lib._uarray._uarray, scipy.linalg._matfuncs_expmscipy.sparse.linalg._propack._zpropackscipy.sparse.linalg._propack._zpropack, scipy.linalg._linalg_pythran)_csparsetoolspandas._libs.tslibs.period, , , scipy.sparse.csgraph._min_spanning_tree, , scipy.special._comb, , , scipy.sparse.linalg._dsolve._superlu, 
, , scipy.sparse._csparsetoolsscipy.sparse.linalg._propack._zpropacknumpy.random._mt19937, scipy.sparse.linalg._propack._spropackscipy.special._ufuncs_cxx, scipy.linalg._linalg_pythranscipy.sparse.csgraph._toolsscipy.sparse.csgraph._tools, scipy.linalg.cython_blasscipy.sparse._csparsetoolspandas._libs.tslibs.vectorized, , , scipy.sparse.csgraph._flow, , scipy.special._ellip_harm_2, , , scipy.sparse.linalg._eigen.arpack._arpack, , , scipy.sparse.linalg._dsolve._superluscipy.sparse.csgraph._toolsnumpy.random._philox, scipy.sparse.linalg._propack._dpropackscipy.special._ufuncs, scipy.linalg.cython_blasscipy.sparse.csgraph._shortest_pathscipy.sparse.csgraph._shortest_path, scipy.linalg._decomp_updatescipy.sparse.linalg._dsolve._superlupandas._libs.ops_dispatch, , , scipy.sparse.csgraph._matching, , scipy.linalg._decomp_interpolative, , , scipy.sparse.linalg._propack._spropack, , , scipy.sparse.linalg._eigen.arpack._arpackscipy.sparse.csgraph._shortest_pathnumpy.random._sfc64, scipy.sparse.linalg._propack._cpropackscipy.special._specfun, scipy.linalg._decomp_updatescipy.sparse.csgraph._traversalscipy.sparse.csgraph._traversal, scipy.sparse._sparsetoolsscipy.sparse.linalg._eigen.arpack._arpackpandas._libs.missing, , , scipy.sparse.csgraph._reordering, , scipy.optimize._bglu_dense, , , scipy.sparse.linalg._propack._dpropack, , , scipy.sparse.linalg._propack._spropackscipy.sparse.csgraph._traversalnumpy.random.mtrand, scipy.sparse.linalg._propack._zpropackscipy.special._comb, scipy.sparse._sparsetoolsscipy.sparse.csgraph._min_spanning_treescipy.sparse.csgraph._min_spanning_tree, _csparsetoolsscipy.sparse.linalg._propack._spropackpandas._libs.hashtable, , scipy.optimize._group_columns, , , scipy.optimize._lsap, , , scipy.sparse.linalg._propack._cpropack, , , scipy.sparse.linalg._propack._dpropackscipy.sparse.csgraph._min_spanning_tree, aclscipy.sparse.csgraph._toolsscipy.special._ellip_harm_2, _csparsetoolsscipy.sparse.csgraph._flowscipy.sparse.csgraph._flow, scipy.sparse._csparsetoolsscipy.sparse.linalg._propack._dpropackpandas._libs.algos, , scipy._lib.messagestream, , scipy.spatial._ckdtree, , , scipy.sparse.linalg._propack._zpropack, , , , scipy.sparse.linalg._propack._cpropackscipy.sparse.csgraph._flow, scipy.sparse.csgraph._shortest_pathscipy.linalg._decomp_interpolative, scipy.sparse._csparsetoolsscipy.sparse.csgraph._matchingscipy.sparse.csgraph._matching, torch_npu._Cscipy.sparse.linalg._dsolve._superluscipy.sparse.linalg._propack._cpropackpandas._libs.interval, , scipy.optimize._trlib._trlib, , scipy.spatial._qhull, , , scipy.sparse.csgraph._tools, , , scipy.sparse.linalg._propack._zpropackscipy.sparse.csgraph._matching, scipy.sparse.csgraph._traversalscipy.optimize._bglu_dense, , scipy.sparse.linalg._dsolve._superluscipy.sparse.csgraph._reorderingscipy.sparse.csgraph._reordering, scipy.sparse.linalg._eigen.arpack._arpackscipy.sparse.linalg._propack._zpropackpandas._libs.lib, , scipy.optimize._lbfgsb, , markupsafe._speedupsscipy.spatial._voronoi, , , scipy.sparse.csgraph._shortest_path, , , scipy.sparse.csgraph._toolsscipy.sparse.csgraph._reordering, scipy.sparse.csgraph._min_spanning_treescipy.optimize._lsap, scipy.sparse.linalg._eigen.arpack._arpack, scipy.optimize._group_columnsscipy.optimize._group_columns, scipy.sparse.linalg._propack._spropackscipy.sparse.csgraph._toolspyarrow._compute, , _moduleTNC, , scipy.spatial._distance_wrap, yaml._yaml, , scipy.sparse.csgraph._traversal, , , scipy.sparse.csgraph._shortest_pathscipy.optimize._group_columns, scipy.sparse.csgraph._flowscipy.spatial._ckdtree, scipy.sparse.linalg._propack._spropackscipy._lib.messagestreamscipy._lib.messagestream, scipy.sparse.linalg._propack._dpropackscipy.sparse.csgraph._shortest_path, pandas._libs.ops, , scipy.optimize._moduleTNC, , scipy.spatial._hausdorff, , , scipy.sparse.csgraph._min_spanning_tree, , psutil._psutil_linux, scipy.sparse.csgraph._traversalscipy._lib.messagestream, scipy.sparse.csgraph._matchingscipy.spatial._qhull, scipy.sparse.linalg._propack._dpropackscipy.optimize._trlib._trlibscipy.optimize._trlib._trlib, scipy.sparse.linalg._propack._cpropackscipy.sparse.csgraph._traversal, pandas._libs.hashing, , scipy.optimize._cobyla, , scipy.spatial.transform._rotation, , , scipy.sparse.csgraph._flow, , zmq.backend.cython._zmq, scipy.sparse.csgraph._min_spanning_treescipy.optimize._trlib._trlib, scipy.sparse.csgraph._reorderingscipy.spatial._voronoi, scipy.sparse.linalg._propack._cpropackscipy.optimize._lbfgsbscipy.optimize._lbfgsb, scipy.sparse.linalg._propack._zpropackscipy.sparse.csgraph._min_spanning_treepandas._libs.arrays, , , scipy.optimize._slsqp, , scipy.optimize._direct, , , scipy.sparse.csgraph._matching, , , cython.cimports.libc.mathscipy.sparse.csgraph._flowscipy.optimize._lbfgsb, scipy.optimize._group_columnsscipy.spatial._distance_wrapscipy.sparse.linalg._propack._zpropack_moduleTNC_moduleTNC, , scipy.sparse.csgraph._toolsscipy.sparse.csgraph._flowpandas._libs.tslib, , scipy.optimize._minpack, , , , , , setproctitle._setproctitlescipy.sparse.csgraph._reordering, , , scipy.sparse.csgraph._matching_moduleTNC, PIL._imagingscipy._lib.messagestreamscipy.spatial._hausdorffscipy.sparse.csgraph._toolsscipy.optimize._moduleTNCscipy.optimize._moduleTNC, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._matchingpandas._libs.sparse, , scipy.optimize._lsq.givens_elimination, , , , , , scipy.optimize._group_columns, Cython.Utils, , scipy.sparse.csgraph._reorderingscipy.optimize._moduleTNC, scipy.optimize._trlib._trlibscipy.spatial.transform._rotationscipy.sparse.csgraph._shortest_pathsentencepiece._sentencepiecescipy.optimize._cobylascipy.optimize._cobyla, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._reorderingpandas._libs.internals, , scipy.optimize._zeros, , , , , , scipy._lib.messagestream, Cython.Plex.Actions, , scipy.optimize._group_columnsscipy.optimize._cobyla, scipy.optimize._lbfgsbscipy.optimize._directscipy.sparse.csgraph._traversalregex._regexscipy.optimize._slsqpscipy.optimize._slsqp, scipy.sparse.csgraph._min_spanning_tree, scipy.optimize._group_columnspandas._libs.indexing, , scipy.optimize._cython_nnls, , , , , scipy.optimize._trlib._trlib, , Cython.Plex.Transitions, , scipy._lib.messagestreamscipy.optimize._slsqp, _moduleTNCscipy.sparse.csgraph._min_spanning_treesetproctitle._setproctitlescipy.optimize._minpackscipy.optimize._minpack, npu_utilsscipy.sparse.csgraph._flow, scipy._lib.messagestreampandas._libs.index, , scipy._lib._uarray._uarray, , , , scipy.optimize._lbfgsb, , , Cython.Plex.Machines, , scipy.optimize._trlib._trlibscipy.optimize._minpack, scipy.optimize._moduleTNCscipy.optimize._lsq.givens_eliminationCython.Utilsscipy.optimize._lsq.givens_elimination, scipy.sparse.csgraph._flowscipy.sparse.csgraph._matchingPIL._imagingft, scipy.optimize._trlib._trlibpandas._libs.writers, , scipy.special._ufuncs_cxx, , , , _moduleTNC, , Cython.Plex.DFA, , , scipy.optimize._lbfgsbscipy.optimize._lsq.givens_elimination, scipy.optimize._cobylascipy.optimize._zerosCython.Plex.Actionsscipy.optimize._zeros, scipy.sparse.csgraph._matchingscipy.sparse.csgraph._reordering, _cffi_backendscipy.optimize._lbfgsbpandas._libs.join, , scipy.special._ufuncs, , , , scipy.optimize._moduleTNC, , Cython.Plex.Scanners, , , _moduleTNCscipy.optimize._zeros, scipy.optimize._slsqpscipy.optimize._cython_nnlsCython.Plex.Transitionsscipy.optimize._cython_nnls, scipy.sparse.csgraph._reorderingscipy.optimize._group_columns, scipy._lib._ccallback_c_moduleTNCpandas._libs.window.aggregations, , scipy.special._specfun, , , , scipy.optimize._cobyla, , Cython.Compiler.Scanning, , , scipy.optimize._moduleTNCscipy.optimize._cython_nnls, scipy.optimize._minpackscipy._lib._uarray._uarrayCython.Plex.Machinesscipy._lib._uarray._uarray, scipy.optimize._group_columnsscipy._lib.messagestream, scipy.linalg._fblasscipy.optimize._moduleTNCpandas._libs.window.indexers, , scipy.special._comb, , , , scipy.optimize._slsqp, , Cython.StringIOTree, , , scipy.optimize._cobylascipy._lib._uarray._uarray, scipy.optimize._lsq.givens_eliminationscipy.special._ufuncs_cxxCython.Plex.DFAscipy.special._ufuncs_cxx, scipy._lib.messagestreamscipy.optimize._trlib._trlib, scipy.linalg._flapackscipy.optimize._cobylapandas._libs.reshape, , scipy.special._ellip_harm_2, , , , scipy.optimize._minpack, , Cython.Compiler.Code, , , scipy.optimize._slsqpscipy.special._ufuncs_cxx, scipy.optimize._zerosscipy.special._ufuncsCython.Plex.Scannersscipy.special._ufuncs, scipy.optimize._trlib._trlibscipy.optimize._lbfgsbscipy.linalg.cython_lapack, scipy.optimize._slsqppandas._libs.groupby, , scipy.linalg._decomp_interpolative, , , , scipy.optimize._lsq.givens_elimination, , , google._upb._message, , scipy.optimize._minpackscipy.special._ufuncs, scipy.optimize._cython_nnlsscipy.special._specfunCython.Compiler.Scanningscipy.special._specfun, scipy.optimize._lbfgsb_moduleTNCscipy.linalg._cythonized_array_utilsscipy.optimize._minpackpandas._libs.json, , scipy.optimize._bglu_dense, , , , , scipy.optimize._zeros, , , , , scipy.optimize._lsq.givens_eliminationscipy.special._specfun, scipy._lib._uarray._uarraymsgspec._corescipy.special._combCython.StringIOTreescipy.special._comb, _moduleTNCscipy.optimize._moduleTNCscipy.linalg._solve_toeplitzscipy.optimize._lsq.givens_elimination, , pandas._libs.parsers, , scipy.optimize._lsap, , , , , scipy.optimize._cython_nnls, , scipy.linalg._decomp_lu_cythonscipy.optimize._zeros, , scipy.optimize._zerosscipy.special._comb, scipy.special._ufuncs_cxxscipy.special._ellip_harm_2Cython.Compiler.Codepyarrow.libscipy.special._ellip_harm_2, scipy.optimize._moduleTNCscipy.optimize._cobylascipy.linalg._matfuncs_sqrtm_triu, pandas._libs.testing, , scipy.spatial._ckdtree, , , , , scipy._lib._uarray._uarray, , , scipy.optimize._cython_nnls, scipy.optimize._cython_nnlsscipy.special._ellip_harm_2, scipy.special._ufuncsscipy.linalg._decomp_interpolativegoogle._upb._messagepandas._libs.tslibs.ccalendarscipy.linalg._decomp_interpolative, scipy.optimize._cobylascipy.optimize._slsqpscipy.linalg._matfuncs_expm, , pyarrow._parquet, , scipy.spatial._qhull, , , , scipy.special._ufuncs_cxx, , scipy._lib._uarray._uarrayscipy.linalg._linalg_pythran, , , scipy._lib._uarray._uarrayscipy.linalg._decomp_interpolative, scipy.special._specfunscipy.optimize._bglu_densepandas._libs.tslibs.np_datetimescipy.optimize._bglu_dense, scipy.optimize._slsqpscipy.optimize._minpackscipy.special._ufuncs_cxx, , msgspec._corepyarrow._fs, , scipy.spatial._voronoi, , , , scipy.special._ufuncs, , scipy.linalg.cython_blasscipy.special._ufuncs, , scipy.special._ufuncs_cxx, scipy.optimize._bglu_dense, scipy.special._combscipy.optimize._lsappandas._libs.tslibs.dtypesscipy.optimize._lsap, scipy.optimize._minpackscipy.optimize._lsq.givens_elimination, scipy.linalg._decomp_updatepyarrow._azurefs, pyarrow.lib, scipy.spatial._distance_wrap, , , , scipy.special._specfun, , scipy.special._specfun, , scipy.special._ufuncsscipy.optimize._lsap, , scipy.special._ellip_harm_2scipy.spatial._ckdtreepandas._libs.tslibs.basescipy.spatial._ckdtree, scipy.optimize._lsq.givens_eliminationscipy.optimize._zeros, scipy.sparse._sparsetoolspyarrow._hdfs, , pandas._libs.tslibs.ccalendarscipy.spatial._hausdorff, , , , scipy.special._comb, , scipy.special._comb, , , scipy.special._specfunscipy.spatial._ckdtree, , scipy.linalg._decomp_interpolativescipy.spatial._qhullpandas._libs.tslibs.nattypescipy.spatial._qhull, scipy.optimize._zerosscipy.optimize._cython_nnls_csparsetoolsscipy.special._ellip_harm_2pyarrow._gcsfs, , pandas._libs.tslibs.np_datetimescipy.spatial.transform._rotation, , , , scipy.special._ellip_harm_2, , , , , scipy.special._combscipy.spatial._qhull, , scipy.optimize._bglu_densescipy.spatial._voronoipandas._libs.tslibs.timezonesscipy.spatial._voronoi, scipy.optimize._cython_nnlsscipy._lib._uarray._uarrayscipy.sparse._csparsetoolsscipy.linalg._decomp_interpolativepyarrow._s3fs, , pandas._libs.tslibs.dtypesscipy.optimize._direct, , , , scipy.linalg._decomp_interpolative, , , , , scipy.special._ellip_harm_2scipy.spatial._voronoi, scipy.optimize._lsapscipy.spatial._distance_wrap, pandas._libs.tslibs.fieldsscipy.spatial._distance_wrap, scipy._lib._uarray._uarrayscipy.special._ufuncs_cxxscipy.sparse.linalg._dsolve._superluscipy.optimize._bglu_densexxhash._xxhash, , pandas._libs.tslibs.base, , setproctitle._setproctitle, , scipy.optimize._bglu_dense, , , , , scipy.linalg._decomp_interpolativescipy.spatial._distance_wrap, scipy.spatial._ckdtreescipy.spatial._hausdorffpandas._libs.tslibs.timedeltasscipy.spatial._hausdorff, , scipy.special._ufuncs_cxxscipy.special._ufuncsscipy.sparse.linalg._eigen.arpack._arpackscipy.optimize._lsappyarrow._acero, , pandas._libs.tslibs.nattype, , , , Cython.Utilsscipy.optimize._lsap, , , , , scipy.optimize._bglu_densescipy.spatial._hausdorff, scipy.spatial._qhullscipy.spatial.transform._rotationpandas._libs.tslibs.tzconversionscipy.spatial.transform._rotation, scipy.special._ufuncs, scipy.special._specfunscipy.sparse.linalg._propack._spropackscipy.spatial._ckdtreepyarrow._csv, , pandas._libs.tslibs.timezones, , , , Cython.Plex.Actions, scipy.spatial._ckdtree, , , , scipy.optimize._lsapscipy.spatial.transform._rotation, scipy.spatial._voronoiscipy.optimize._directpandas._libs.tslibs.timestampsscipy.optimize._direct, scipy.special._specfun, scipy.special._combscipy.sparse.linalg._propack._dpropackscipy.spatial._qhull, pyarrow._json, , pandas._libs.tslibs.fields, , , Cython.Plex.Transitions, , scipy.spatial._qhull, , scipy.sparse.linalg._propack._cpropack, scipy.spatial._ckdtreescipy.optimize._direct, scipy.spatial._distance_wrappandas._libs.propertiessetproctitle._setproctitle, setproctitle._setproctitlescipy.special._comb, scipy.special._ellip_harm_2scipy.spatial._voronoi, pyarrow._substrait, pandas._libs.tslibs.timedeltas, , , Cython.Plex.Machines, , , scipy.spatial._voronoi, , scipy.sparse.linalg._propack._zpropack, scipy.spatial._qhull, setproctitle._setproctitlescipy.spatial._hausdorff, pandas._libs.tslibs.offsets, Cython.UtilsCython.Utilsscipy.special._ellip_harm_2, scipy.linalg._decomp_interpolativescipy.spatial._distance_wrap, pyarrow._dataset, pandas._libs.tslibs.tzconversion, Cython.UtilsCython.Plex.DFA, , , , scipy.spatial._distance_wrap, , scipy.sparse.csgraph._tools, scipy.spatial._voronoi, scipy.spatial.transform._rotation, , pandas._libs.tslibs.strptimeCython.Plex.ActionsCython.Plex.Actionsscipy.linalg._decomp_interpolative, scipy.optimize._bglu_densescipy.spatial._hausdorff, pyarrow._dataset_orc, pandas._libs.tslibs.timestamps, Cython.Plex.ActionsCython.Plex.Scanners, , , , scipy.spatial._hausdorff, scipy.sparse.csgraph._shortest_path, , , scipy.spatial._distance_wrap, scipy.optimize._direct, , pandas._libs.tslibs.parsingCython.Plex.TransitionsCython.Plex.Transitionsscipy.optimize._bglu_dense, scipy.optimize._lsapscipy.spatial.transform._rotationscipy.sparse.csgraph._traversalpyarrow._parquet_encryption, pandas._libs.propertiesCython.Plex.TransitionsCython.Compiler.Scanning, , , , , scipy.spatial.transform._rotation, , , , scipy.spatial._hausdorff, , , setproctitle._setproctitlepandas._libs.tslibs.conversionCython.Plex.MachinesCython.Plex.Machinesscipy.optimize._lsap, scipy.spatial._ckdtreescipy.optimize._directscipy.sparse.csgraph._min_spanning_treepyarrow._dataset_parquet_encryption, pandas._libs.tslibs.offsetsCython.Plex.MachinesCython.StringIOTree, , , , , scipy.optimize._direct, , , , scipy.spatial.transform._rotation, , pandas._libs.tslibs.period, Cython.UtilsCython.Plex.DFACython.Plex.DFAscipy.spatial._ckdtreescipy.spatial._qhullscipy.sparse.csgraph._flow, pyarrow._dataset_parquetsetproctitle._setproctitle, pandas._libs.tslibs.strptimeCython.Plex.DFA, Cython.Compiler.Code, , , , , , setproctitle._setproctitlescipy.optimize._direct, , , pandas._libs.tslibs.vectorizedCython.Plex.Actions, Cython.Plex.ScannersCython.Plex.Scannersscipy.spatial._qhullscipy.spatial._voronoiscipy.sparse.csgraph._matching, Cython.Utilspandas._libs.tslibs.parsing, Cython.Plex.Scanners, , google._upb._message, , , , , , Cython.Utils, , setproctitle._setproctitle, pandas._libs.ops_dispatchCython.Plex.Transitions__triton_launcherCython.Compiler.ScanningCython.Compiler.Scanningscipy.spatial._voronoiscipy.spatial._distance_wrapscipy.sparse.csgraph._reordering, Cython.Plex.Actions, pandas._libs.tslibs.conversionCython.Compiler.Scanning, , ,  (total: , , , , , Cython.Plex.Actions, msgspec._core, , Cython.Utilspandas._libs.missingCython.Plex.Machines174Cython.StringIOTreeCython.StringIOTreescipy.spatial._distance_wrapscipy.spatial._hausdorffscipy.optimize._group_columns, Cython.Plex.Transitionspandas._libs.tslibs.periodCython.StringIOTree, , , , ), , , , , Cython.Plex.Transitions, , , pyarrow.libCython.Plex.Actionspandas._libs.hashtableCython.Plex.DFA
Cython.Compiler.CodeCython.Compiler.Codescipy.spatial._hausdorffscipy.spatial.transform._rotationscipy._lib.messagestream, , Cython.Plex.Machinespandas._libs.tslibs.vectorizedCython.Compiler.Code, , , , , , , , scipy.optimize._trlib._trlibCython.Plex.Machines, , , pandas._libs.tslibs.ccalendarCython.Plex.Transitionspandas._libs.algosCython.Plex.Scannersgoogle._upb._messagegoogle._upb._messagescipy.spatial.transform._rotationscipy.optimize._direct, , Cython.Plex.DFApandas._libs.ops_dispatchgoogle._upb._message, , , , , scipy.optimize._lbfgsbCython.Plex.DFA, , , , pandas._libs.tslibs.np_datetime, Cython.Plex.Machinespandas._libs.intervalCython.Compiler.Scanning, scipy.optimize._direct, , setproctitle._setproctitleCython.Plex.Scannersmsgspec._corepandas._libs.missing, msgspec._core, , , msgspec._core_moduleTNCCython.Plex.Scanners, , , , , pandas._libs.tslibs.dtypesCython.Plex.DFApandas._libs.lib, Cython.StringIOTree, , , setproctitle._setproctitleCython.Compiler.ScanningCython.Utilspandas._libs.hashtablepyarrow.lib, , , pyarrow.lib, scipy.optimize._moduleTNCpyarrow.libCython.Compiler.Scanning, , , , , pandas._libs.tslibs.baseCython.Plex.Scannerspyarrow._compute, Cython.Compiler.Code, , , Cython.StringIOTreeCython.UtilsCython.Plex.Actionspandas._libs.algospandas._libs.tslibs.ccalendar, , , pandas._libs.tslibs.ccalendarscipy.optimize._cobyla, pandas._libs.tslibs.ccalendarCython.StringIOTree, , , , , pandas._libs.tslibs.nattypeCython.Compiler.Scanningpandas._libs.ops, , google._upb._message, , Cython.Compiler.CodeCython.Plex.ActionsCython.Plex.Transitionspandas._libs.intervalpandas._libs.tslibs.np_datetime, , , pandas._libs.tslibs.np_datetimescipy.optimize._slsqppandas._libs.tslibs.np_datetimeCython.Compiler.Code, , , , , pandas._libs.tslibs.timezones, Cython.StringIOTreepandas._libs.hashing, , , google._upb._message, Cython.Plex.TransitionsCython.Plex.Machinespandas._libs.libpandas._libs.tslibs.dtypes, msgspec._core, , pandas._libs.tslibs.dtypesscipy.optimize._minpackpandas._libs.tslibs.dtypes, google._upb._message, , , , pandas._libs.tslibs.fields, Cython.Compiler.Codepandas._libs.arrays, , , scipy.optimize._lsq.givens_eliminationCython.Plex.MachinesCython.Plex.DFApyarrow._computepandas._libs.tslibs.base, msgspec._core, , , pyarrow.libpandas._libs.tslibs.basepandas._libs.tslibs.base, , , , , pandas._libs.tslibs.timedeltasmsgspec._coregoogle._upb._message, pandas._libs.tslib, , , scipy.optimize._zerosCython.Plex.DFACython.Plex.Scannerspandas._libs.opspandas._libs.tslibs.nattype, , pyarrow.lib, pandas._libs.tslibs.ccalendarpandas._libs.tslibs.nattypepandas._libs.tslibs.nattype, , , , , , pandas._libs.tslibs.tzconversionpyarrow.lib, pandas._libs.sparse, , , msgspec._corescipy.optimize._cython_nnlsCython.Plex.ScannersCython.Compiler.Scanningpandas._libs.hashingpandas._libs.tslibs.timezones, , pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetimepandas._libs.tslibs.timezonespandas._libs.tslibs.timezones, , , , , , pandas._libs.tslibs.timestampspandas._libs.tslibs.ccalendar, pandas._libs.internals, , , scipy._lib._uarray._uarraypyarrow.libCython.Compiler.ScanningCython.StringIOTreepandas._libs.arrayspandas._libs.tslibs.fields, , pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypespandas._libs.tslibs.fieldspandas._libs.tslibs.fields, , , , , , pandas._libs.propertiespandas._libs.tslibs.np_datetime, pandas._libs.indexing, , , scipy.special._ufuncs_cxxpandas._libs.tslibs.ccalendarCython.StringIOTreeCython.Compiler.Codepandas._libs.tslibpandas._libs.tslibs.timedeltas, , pandas._libs.tslibs.dtypes, pandas._libs.tslibs.basepandas._libs.tslibs.timedeltaspandas._libs.tslibs.timedeltas, , , , , , pandas._libs.tslibs.offsetspandas._libs.tslibs.dtypes, pandas._libs.index, , , scipy.special._ufuncspandas._libs.tslibs.np_datetimeCython.Compiler.Codegoogle._upb._messagepandas._libs.sparsepandas._libs.tslibs.tzconversion, , pandas._libs.tslibs.base, pandas._libs.tslibs.nattypepandas._libs.tslibs.tzconversionpandas._libs.tslibs.tzconversion, , , , , pandas._libs.tslibs.strptimepandas._libs.tslibs.base, pandas._libs.writers, , , , scipy.special._specfunpandas._libs.tslibs.dtypesgoogle._upb._messagepandas._libs.internalspandas._libs.tslibs.timestamps, , pandas._libs.tslibs.nattype, msgspec._corepandas._libs.tslibs.timezonespandas._libs.tslibs.timestampspandas._libs.tslibs.timestamps, , , , pandas._libs.tslibs.parsingpandas._libs.tslibs.nattype, pandas._libs.join, , , , , scipy.special._combpandas._libs.tslibs.basepandas._libs.indexingpandas._libs.properties, , pandas._libs.tslibs.timezones, msgspec._corepandas._libs.tslibs.fieldspandas._libs.propertiespyarrow.libpandas._libs.properties, , , , pandas._libs.tslibs.conversionpandas._libs.tslibs.timezones, pandas._libs.window.aggregations, , , , , scipy.special._ellip_harm_2pandas._libs.tslibs.nattypepandas._libs.indexpandas._libs.tslibs.offsets, , pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltaspandas._libs.tslibs.offsetspyarrow.libpandas._libs.tslibs.ccalendarpandas._libs.tslibs.offsets, , , , pandas._libs.tslibs.periodpandas._libs.tslibs.fields, pandas._libs.window.indexers, , , , , scipy.linalg._decomp_interpolativepandas._libs.tslibs.timezonespandas._libs.writerspandas._libs.tslibs.strptime, , pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversionpandas._libs.tslibs.strptimepandas._libs.tslibs.ccalendarpandas._libs.tslibs.np_datetimepandas._libs.tslibs.strptime, , , , pandas._libs.tslibs.vectorizedpandas._libs.tslibs.timedeltas, pandas._libs.reshape, , , , , scipy.optimize._bglu_densepandas._libs.tslibs.fieldspandas._libs.joinpandas._libs.tslibs.parsing, , pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestampspandas._libs.tslibs.parsingpandas._libs.tslibs.np_datetimepandas._libs.tslibs.dtypespandas._libs.tslibs.parsing, , , , pandas._libs.ops_dispatchpandas._libs.tslibs.tzconversion, pandas._libs.groupby, , , , , scipy.optimize._lsappandas._libs.tslibs.timedeltaspandas._libs.window.aggregationspandas._libs.tslibs.conversion, , pandas._libs.tslibs.timestamps, pandas._libs.propertiespandas._libs.tslibs.conversionpandas._libs.tslibs.dtypespandas._libs.tslibs.basepandas._libs.tslibs.conversion, , , , pandas._libs.missingpandas._libs.tslibs.timestamps, pandas._libs.json, , , , , scipy.spatial._ckdtreepandas._libs.tslibs.tzconversionpandas._libs.window.indexerspandas._libs.tslibs.period, , pandas._libs.properties, pandas._libs.tslibs.offsetspandas._libs.tslibs.periodpandas._libs.tslibs.basepandas._libs.tslibs.nattypepandas._libs.tslibs.period, , , , pandas._libs.hashtablepandas._libs.properties, pandas._libs.parsers, , , , , scipy.spatial._qhullpandas._libs.tslibs.timestampspandas._libs.reshapepandas._libs.tslibs.vectorized, , pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptimepandas._libs.tslibs.vectorizedpandas._libs.tslibs.nattypepandas._libs.tslibs.timezonespandas._libs.tslibs.vectorized, , , , pandas._libs.algospandas._libs.tslibs.offsets, pandas._libs.testing, , , , , scipy.spatial._voronoipandas._libs.propertiespandas._libs.groupbypandas._libs.ops_dispatch, , pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsingpandas._libs.ops_dispatchpandas._libs.tslibs.timezonespandas._libs.tslibs.fieldspandas._libs.ops_dispatch, , , , pandas._libs.intervalpandas._libs.tslibs.strptime, pyarrow._parquet, , , , , scipy.spatial._distance_wrappandas._libs.tslibs.offsetspandas._libs.jsonpandas._libs.missing, , pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversionpandas._libs.missingpandas._libs.tslibs.fieldspandas._libs.tslibs.timedeltaspandas._libs.missing, , , , pandas._libs.libpandas._libs.tslibs.parsing, pyarrow._fs, , , , , scipy.spatial._hausdorffpandas._libs.tslibs.strptimepandas._libs.parserspandas._libs.hashtable, , pandas._libs.tslibs.conversion, pandas._libs.tslibs.periodpandas._libs.hashtablepandas._libs.tslibs.timedeltaspandas._libs.tslibs.tzconversionpandas._libs.hashtable, , , , pyarrow._computepandas._libs.tslibs.conversion, pyarrow._azurefs, , , , , scipy.spatial.transform._rotationpandas._libs.tslibs.parsingpandas._libs.testingpandas._libs.algos, , pandas._libs.tslibs.period, pandas._libs.tslibs.vectorizedpandas._libs.algospandas._libs.tslibs.tzconversionpandas._libs.tslibs.timestampspandas._libs.algos, , , , pandas._libs.opspandas._libs.tslibs.period, pyarrow._hdfs, , , , , scipy.optimize._directpandas._libs.tslibs.conversionpyarrow._parquetpandas._libs.interval, , pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatchpandas._libs.intervalpandas._libs.tslibs.timestampspandas._libs.propertiespandas._libs.interval, , , pandas._libs.hashing, pandas._libs.tslibs.vectorized, pyarrow._gcsfs, , , , , pandas._libs.tslibs.periodpyarrow._fspandas._libs.lib, setproctitle._setproctitle, pandas._libs.ops_dispatch, pandas._libs.missingpandas._libs.libpandas._libs.propertiespandas._libs.tslibs.offsetspandas._libs.lib, , , pandas._libs.arrayspandas._libs.ops_dispatch, pyarrow._s3fs, , , , , , pandas._libs.tslibs.vectorizedpyarrow._azurefspyarrow._compute, , pandas._libs.missing, Cython.Utilspandas._libs.hashtablepyarrow._computepandas._libs.tslibs.offsetspandas._libs.tslibs.strptimepyarrow._compute, , , pandas._libs.tslibpandas._libs.missing, xxhash._xxhash, , , , , , pandas._libs.ops_dispatchpyarrow._hdfspandas._libs.ops, , pandas._libs.hashtable, Cython.Plex.Actionspandas._libs.algospandas._libs.opspandas._libs.tslibs.strptimepandas._libs.tslibs.parsingpandas._libs.ops, , , pandas._libs.sparsepandas._libs.hashtable, pyarrow._acero, , , , , , pandas._libs.missingpyarrow._gcsfspandas._libs.hashing, , pandas._libs.algos, Cython.Plex.Transitionspandas._libs.intervalpandas._libs.hashingpandas._libs.tslibs.parsingpandas._libs.tslibs.conversionpandas._libs.hashing, , , pandas._libs.internalspandas._libs.algos, pyarrow._csv, , , , , , pandas._libs.hashtablepyarrow._s3fspandas._libs.arrays, , , pandas._libs.interval, Cython.Plex.Machinespandas._libs.libpandas._libs.arrayspandas._libs.tslibs.conversionpandas._libs.tslibs.periodpandas._libs.arrays, , xxhash._xxhashpandas._libs.indexingpandas._libs.interval, pyarrow._json, , , , , , pandas._libs.algospandas._libs.tslib, , , pandas._libs.lib, Cython.Plex.DFApyarrow._computepandas._libs.tslibpandas._libs.tslibs.periodpandas._libs.tslibs.vectorizedpandas._libs.tslib, , pyarrow._aceropandas._libs.indexpandas._libs.lib, pyarrow._substrait, , , , , , pandas._libs.intervalpandas._libs.sparse, , , pyarrow._compute, Cython.Plex.Scannerspandas._libs.opspandas._libs.sparsepandas._libs.tslibs.vectorizedpandas._libs.ops_dispatchpandas._libs.sparse, , pyarrow._csvpandas._libs.writerspyarrow._compute, pyarrow._dataset, , , , , , pandas._libs.libpandas._libs.internals, , , pandas._libs.ops, Cython.Compiler.Scanningpandas._libs.hashingpandas._libs.internalspandas._libs.ops_dispatchpandas._libs.missingpandas._libs.internals, , pyarrow._jsonpandas._libs.joinpandas._libs.ops, pyarrow._dataset_orc, , , , , , pyarrow._computepandas._libs.indexing, , , pandas._libs.hashing, Cython.StringIOTreepandas._libs.arrayspandas._libs.indexingpandas._libs.missingpandas._libs.hashtablepandas._libs.indexing, , pyarrow._substraitpandas._libs.window.aggregationspandas._libs.hashing, pyarrow._parquet_encryption, , , , , , pandas._libs.opspandas._libs.index, , , pandas._libs.arrays, Cython.Compiler.Codepandas._libs.tslibpandas._libs.indexpandas._libs.hashtablepandas._libs.algospandas._libs.index, , pyarrow._datasetpandas._libs.window.indexerspandas._libs.arrays, pyarrow._dataset_parquet_encryption, , , , , , pandas._libs.hashingpandas._libs.writers, , , pandas._libs.tslib, pandas._libs.sparsepandas._libs.writerspandas._libs.algosgoogle._upb._messagepandas._libs.intervalpandas._libs.writers, , pyarrow._dataset_orcpandas._libs.reshapepandas._libs.tslib, pyarrow._dataset_parquet, , , , , pandas._libs.arrayspandas._libs.join, , , pandas._libs.sparse, pandas._libs.internalspandas._libs.joinpandas._libs.intervalpandas._libs.libpandas._libs.join, , pyarrow._parquet_encryptionpandas._libs.groupbypandas._libs.sparse, msgspec._core, , , , , pandas._libs.tslibpandas._libs.window.aggregations, , , , pandas._libs.internalspandas._libs.indexingpandas._libs.window.aggregationspandas._libs.libpyarrow._compute, pandas._libs.window.aggregations, , pyarrow._dataset_parquet_encryption__triton_launcherpandas._libs.jsonpandas._libs.internals, , , , , pyarrow.lib, pandas._libs.sparsepandas._libs.window.indexers,  (total: , , pandas._libs.indexingpandas._libs.indexpandas._libs.window.indexerspyarrow._computepandas._libs.ops, pandas._libs.window.indexers, , pyarrow._dataset_parquet174pandas._libs.parserspandas._libs.indexing, , , , , pandas._libs.tslibs.ccalendar, pandas._libs.internalspandas._libs.reshape), , pandas._libs.indexpandas._libs.writerspandas._libs.reshapepandas._libs.opspandas._libs.hashing, pandas._libs.reshape, , 
pandas._libs.testingpandas._libs.index, , , , , pandas._libs.tslibs.np_datetime, pandas._libs.indexing, pandas._libs.groupby, , pandas._libs.writerspandas._libs.joinpandas._libs.groupbypandas._libs.hashingpandas._libs.arrays, pandas._libs.groupby, __triton_launcher, pyarrow._parquetpandas._libs.writers, , , , , pandas._libs.tslibs.dtypes, pandas._libs.index (total: pandas._libs.json, , pandas._libs.joinpandas._libs.window.aggregationspandas._libs.jsonpandas._libs.arrayspandas._libs.tslib, pandas._libs.json, 174, pyarrow._fspandas._libs.join, , , , , pandas._libs.tslibs.base, pandas._libs.writers)pandas._libs.parsers, , pandas._libs.window.aggregationspandas._libs.window.indexerspandas._libs.parserspandas._libs.tslibpandas._libs.sparse, pandas._libs.parsers, 
, pyarrow._azurefspandas._libs.window.aggregations, , , , , pandas._libs.tslibs.nattype, pandas._libs.joinpandas._libs.testing, , pandas._libs.window.indexerspandas._libs.reshapepandas._libs.testingpandas._libs.sparsepandas._libs.internals, pandas._libs.testing, , pyarrow._hdfspandas._libs.window.indexers, , , , , pandas._libs.tslibs.timezones, pandas._libs.window.aggregationspyarrow._parquet, , pandas._libs.reshapepandas._libs.groupbypyarrow._parquetpandas._libs.internalspandas._libs.indexing, pyarrow._parquet, , pyarrow._gcsfspandas._libs.reshape, , , , , pandas._libs.tslibs.fields, pandas._libs.window.indexerspyarrow._fs, , pandas._libs.groupbypandas._libs.jsonpyarrow._fspandas._libs.indexingpandas._libs.index, pyarrow._fs, , pyarrow._s3fspandas._libs.groupby, , , , , pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.reshapepyarrow._azurefs, , pandas._libs.jsonpandas._libs.parserspyarrow._azurefspandas._libs.indexpandas._libs.writers, pyarrow._azurefs, , xxhash._xxhashpandas._libs.json, , , , , pandas._libs.properties, pandas._libs.groupbypyarrow._hdfs, , pandas._libs.parserspandas._libs.testingpyarrow._hdfspandas._libs.writerspandas._libs.join, pyarrow._hdfs, , pyarrow._aceropandas._libs.parsers, , , , , pandas._libs.tslibs.offsets, pandas._libs.jsonpyarrow._gcsfs, , pandas._libs.testingpyarrow._parquetpyarrow._gcsfspandas._libs.joinpandas._libs.window.aggregations, pyarrow._gcsfs, , pyarrow._csvpandas._libs.testing, , , , , pandas._libs.tslibs.strptime, pandas._libs.parserspyarrow._s3fs, , pyarrow._parquetpyarrow._fspyarrow._s3fspandas._libs.window.aggregationspandas._libs.window.indexers, pyarrow._s3fs, , pyarrow._jsonpyarrow._parquet, , , , , pandas._libs.tslibs.parsing, pandas._libs.testingxxhash._xxhash, , pyarrow._fspyarrow._azurefsxxhash._xxhashpandas._libs.window.indexerspandas._libs.reshape, xxhash._xxhash, , pyarrow._substraitpyarrow._fs, , , , , pandas._libs.tslibs.conversion, pyarrow._parquetpyarrow._acero, , pyarrow._azurefspyarrow._hdfspyarrow._aceropandas._libs.reshapepandas._libs.groupby, pyarrow._acero, , pyarrow._datasetpyarrow._azurefs, , , , , pandas._libs.tslibs.period, pyarrow._fspyarrow._csv, , pyarrow._hdfspyarrow._gcsfspyarrow._csvpandas._libs.groupbypandas._libs.json, pyarrow._csv, , pyarrow._dataset_orcpyarrow._hdfs, , , , , pandas._libs.tslibs.vectorized, pyarrow._azurefspyarrow._json, , pyarrow._gcsfspyarrow._s3fspyarrow._jsonpandas._libs.jsonpandas._libs.parsers, pyarrow._json, , pyarrow._parquet_encryptionpyarrow._gcsfs, , , , , pandas._libs.ops_dispatch, pyarrow._hdfspyarrow._substrait, , pyarrow._s3fsxxhash._xxhashpyarrow._substraitpandas._libs.parserspandas._libs.testing, pyarrow._substrait, , pyarrow._dataset_parquet_encryptionpyarrow._s3fs, , , , , pandas._libs.missing, pyarrow._gcsfspyarrow._dataset, , xxhash._xxhashpyarrow._aceropyarrow._datasetpandas._libs.testingpyarrow._parquet, pyarrow._dataset, , pyarrow._dataset_parquetxxhash._xxhash, , , , , pandas._libs.hashtable, pyarrow._s3fspyarrow._dataset_orc, pyarrow._aceropyarrow._csvpyarrow._dataset_orcpyarrow._parquetpyarrow._fs, pyarrow._dataset_orc, , pyarrow._acero, , , , , pandas._libs.algos, xxhash._xxhashpyarrow._parquet_encryption, pyarrow._csv, pyarrow._jsonpyarrow._parquet_encryptionpyarrow._fspyarrow._azurefs, pyarrow._parquet_encryption, , pyarrow._csv, __triton_launcher, , , , pandas._libs.interval, pyarrow._aceropyarrow._dataset_parquet_encryption, pyarrow._json (total: pyarrow._substraitpyarrow._dataset_parquet_encryptionpyarrow._azurefspyarrow._hdfs, pyarrow._dataset_parquet_encryption, , pyarrow._json, 174, , , , pandas._libs.lib, pyarrow._csvpyarrow._dataset_parquet, pyarrow._substrait)pyarrow._datasetpyarrow._dataset_parquetpyarrow._hdfspyarrow._gcsfs, pyarrow._dataset_parquet, pyarrow._substrait, 
, , , pyarrow._computepyarrow._json, pyarrow._datasetpyarrow._dataset_orcpyarrow._gcsfspyarrow._s3fs, , pyarrow._dataset, , , , , pandas._libs.opspyarrow._substrait, , pyarrow._dataset_orc__triton_launcherpyarrow._parquet_encryptionpyarrow._s3fs, xxhash._xxhash, , __triton_launcherpyarrow._dataset_orc,  (total: , __triton_launcher, , pandas._libs.hashingpyarrow._dataset (total: , pyarrow._parquet_encryption174pyarrow._dataset_parquet_encryption (total: xxhash._xxhashpyarrow._acero, , 174pyarrow._parquet_encryption, ), 174, , pandas._libs.arrayspyarrow._dataset_orc), pyarrow._dataset_parquet_encryption
pyarrow._dataset_parquet)pyarrow._aceropyarrow._csv, , 
pyarrow._dataset_parquet_encryption, 
, , pandas._libs.tslibpyarrow._parquet_encryption, pyarrow._dataset_parquetpyarrow._csvpyarrow._json, , pyarrow._dataset_parquet, , pandas._libs.sparsepyarrow._dataset_parquet_encryptionpyarrow._jsonpyarrow._substrait, , , , , __triton_launcherpandas._libs.internalspyarrow._dataset_parquetpyarrow._substraitpyarrow._dataset (total: , , , 174pandas._libs.indexing, pyarrow._datasetpyarrow._dataset_orc), __triton_launcher, , , 
pandas._libs.index (total: __triton_launcherpyarrow._dataset_orcpyarrow._parquet_encryption174,  (total: , , ), pandas._libs.writers174pyarrow._parquet_encryptionpyarrow._dataset_parquet_encryption
__triton_launcher, ), ,  (total: pandas._libs.join
pyarrow._dataset_parquet_encryptionpyarrow._dataset_parquet, 174, pyarrow._dataset_parquet)pandas._libs.window.aggregations
, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, , __triton_launcherpyarrow._hdfs (total: , , 174__triton_launcherpyarrow._gcsfs) (total: , 
174pyarrow._s3fs)
, xxhash._xxhash, pyarrow._acero, pyarrow._csv, pyarrow._json, pyarrow._substrait, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, __triton_launcher (total: 174)
[2025-12-23 01:58:32] DataParallelController hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/data_parallel_controller.py", line 551, in run_data_parallel_controller_process
    controller = DataParallelController(
                 ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/data_parallel_controller.py", line 168, in __init__
    self.launch_dp_attention_schedulers(server_args, port_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/data_parallel_controller.py", line 374, in launch_dp_attention_schedulers
    self.launch_tensor_parallel_group(
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/data_parallel_controller.py", line 461, in launch_tensor_parallel_group
    scheduler_info.append(scheduler_pipe_readers[i].recv())
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
          ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 399, in _recv
    raise EOFError
EOFError

[2025-12-23 01:58:32] Received sigquit from a child process. It usually means the child failed.
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
The nic name matched is enp23s0f3
The nic name matched is enp23s0f3
Nic name: enp23s0f3
